{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN Classification - Diabetes Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGzGn4oLf1r1oAyRjRXX5T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VitikaJain25/HealthCareNLPCourse/blob/main/ANN_Classification_Diabetes_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kMVX9LNdFivz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes = pd.read_csv(\"https://raw.githubusercontent.com/VitikaJain25/MLDataSets/main/diabetes.csv\")\n",
        "diabetes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "QXKI6W0vGFX2",
        "outputId": "ff4c5234-908f-4858-d959-addbb1bb6812"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                       0.627   50        1  \n",
              "1                       0.351   31        0  \n",
              "2                       0.672   32        1  \n",
              "3                       0.167   21        0  \n",
              "4                       2.288   33        1  \n",
              "..                        ...  ...      ...  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73a59071-2b7c-4f40-ab99-fb44d9b6f79d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73a59071-2b7c-4f40-ab99-fb44d9b6f79d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73a59071-2b7c-4f40-ab99-fb44d9b6f79d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73a59071-2b7c-4f40-ab99-fb44d9b6f79d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Manipulation"
      ],
      "metadata": {
        "id": "8-mhjU0qHY__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All data is numerical\n",
        "diabetes.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HmjViQpHKdW",
        "outputId": "a2be3ed7-bffc-4e07-e9b6-8712173707d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes.describe()\n",
        "# Problem is Glucose, BP, Insulin cannot be 0.\n",
        "# Outcome = 0 mean person is not diabetic, 1 means person is diabetic."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "PsnpR99eHfJ0",
        "outputId": "f9fc74bd-2823-4241-c273-00a15adb7996"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
              "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
              "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
              "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
              "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
              "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
              "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
              "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
              "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
              "\n",
              "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
              "count  768.000000                768.000000  768.000000  768.000000  \n",
              "mean    31.992578                  0.471876   33.240885    0.348958  \n",
              "std      7.884160                  0.331329   11.760232    0.476951  \n",
              "min      0.000000                  0.078000   21.000000    0.000000  \n",
              "25%     27.300000                  0.243750   24.000000    0.000000  \n",
              "50%     32.000000                  0.372500   29.000000    0.000000  \n",
              "75%     36.600000                  0.626250   41.000000    1.000000  \n",
              "max     67.100000                  2.420000   81.000000    1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d826046-0968-456c-8cfb-455fb4f33fc1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d826046-0968-456c-8cfb-455fb4f33fc1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d826046-0968-456c-8cfb-455fb4f33fc1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d826046-0968-456c-8cfb-455fb4f33fc1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Pregnancies column as it can be zero. Other columns cannot be zero.\n",
        "data_raw = diabetes.drop(['Pregnancies', 'Outcome'], axis = 1)"
      ],
      "metadata": {
        "id": "rUUa477wIEbi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other columns cannot be zero, so replacing 0 by np.nan to find missing values.\n",
        "data_raw.replace(0, np.nan, inplace = True)"
      ],
      "metadata": {
        "id": "gl-3uBufIaIL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the missing values.\n",
        "data_raw.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EekDlJQlIkJR",
        "outputId": "5afc6cfa-1004-44b7-f7d4-89484a1f2856"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Insulin                     374\n",
              "SkinThickness               227\n",
              "BloodPressure                35\n",
              "BMI                          11\n",
              "Glucose                       5\n",
              "DiabetesPedigreeFunction      0\n",
              "Age                           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handeling Missing Values"
      ],
      "metadata": {
        "id": "8hUyR8ZvJTbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If data is continous, replace by Mean.\n",
        "# If data is discrete, replace by Median.\n",
        "# If data is non-numerical, replace by Mode.\n",
        "\n",
        "# Using unique() to find out the type of values (continous, discrete)\n",
        "data_raw['Insulin'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmM1JDntJRfQ",
        "outputId": "c14eec0d-b5cf-4a75-e4c0-9a9b4f9f619b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ nan,  94., 168.,  88., 543., 846., 175., 230.,  83.,  96., 235.,\n",
              "       146., 115., 140., 110., 245.,  54., 192., 207.,  70., 240.,  82.,\n",
              "        36.,  23., 300., 342., 304., 142., 128.,  38., 100.,  90., 270.,\n",
              "        71., 125., 176.,  48.,  64., 228.,  76., 220.,  40., 152.,  18.,\n",
              "       135., 495.,  37.,  51.,  99., 145., 225.,  49.,  50.,  92., 325.,\n",
              "        63., 284., 119., 204., 155., 485.,  53., 114., 105., 285., 156.,\n",
              "        78., 130.,  55.,  58., 160., 210., 318.,  44., 190., 280.,  87.,\n",
              "       271., 129., 120., 478.,  56.,  32., 744., 370.,  45., 194., 680.,\n",
              "       402., 258., 375., 150.,  67.,  57., 116., 278., 122., 545.,  75.,\n",
              "        74., 182., 360., 215., 184.,  42., 132., 148., 180., 205.,  85.,\n",
              "       231.,  29.,  68.,  52., 255., 171.,  73., 108.,  43., 167., 249.,\n",
              "       293.,  66., 465.,  89., 158.,  84.,  72.,  59.,  81., 196., 415.,\n",
              "       275., 165., 579., 310.,  61., 474., 170., 277.,  60.,  14.,  95.,\n",
              "       237., 191., 328., 250., 480., 265., 193.,  79.,  86., 326., 188.,\n",
              "       106.,  65., 166., 274.,  77., 126., 330., 600., 185.,  25.,  41.,\n",
              "       272., 321., 144.,  15., 183.,  91.,  46., 440., 159., 540., 200.,\n",
              "       335., 387.,  22., 291., 392., 178., 127., 510.,  16., 112.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(data_raw['Insulin'].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7zXZWJBJ15g",
        "outputId": "3f70652d-a6db-41fd-e726-a2b91631b335"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156.0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace Missing values with Mean for \"Insulin\" column.\n",
        "# Replacing nan value with Mean value for the column \"Insulin\".\n",
        "data_raw['Insulin'].replace(np.nan, np.round(data_raw['Insulin'].mean()), inplace = True)"
      ],
      "metadata": {
        "id": "3lyzZRQjJ8AR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verfying the values for Insulin column.\n",
        "data_raw.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "# Insuline column now has 0 missing / nan values."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gXhfUl8KTyn",
        "outputId": "1a8b93b7-5873-45c4-9b8b-6cfd47992255"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SkinThickness               227\n",
              "BloodPressure                35\n",
              "BMI                          11\n",
              "Glucose                       5\n",
              "Insulin                       0\n",
              "DiabetesPedigreeFunction      0\n",
              "Age                           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  If we want to remove missing or nan values from multiple columns, then instead of doing it one by one we can use Imputer\n",
        "*   The data type changes from Dataframe to Array.\n",
        "*   Simple Imputer targets only nan values that is why we converted 0 values to nan values before replacing with mean value.\n",
        "*   If we do not want to use an imputer, then we can directly convert the 0 values to mean value (no need to convert to nan)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ki_vz9YRKhpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Data type changes from Dataframe to Array.\n",
        "from sklearn.impute import SimpleImputer\n",
        "# Strategy = 'median', 'mean', 'mode'\n",
        "impute = SimpleImputer(strategy = 'median')\n",
        "data_array = impute.fit_transform(data_raw)"
      ],
      "metadata": {
        "id": "tfdRJPGNKhFt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWk7oK-cLDYa",
        "outputId": "acfb57c5-d6d8-4c86-9a66-baa86ab98802"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[148.   ,  72.   ,  35.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [ 85.   ,  66.   ,  29.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [183.   ,  64.   ,  29.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [121.   ,  72.   ,  23.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [126.   ,  60.   ,  29.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [ 93.   ,  70.   ,  31.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So we have to convert the array back to a Dataframe.\n",
        "diabetes_df = pd.DataFrame(data_array, columns = data_raw.columns)\n",
        "diabetes_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "T9EYpfB2LPq3",
        "outputId": "7b2b03c7-b3e8-46a6-dcb5-2207e00c437a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0      148.0           72.0           35.0    156.0  33.6   \n",
              "1       85.0           66.0           29.0    156.0  26.6   \n",
              "2      183.0           64.0           29.0    156.0  23.3   \n",
              "3       89.0           66.0           23.0     94.0  28.1   \n",
              "4      137.0           40.0           35.0    168.0  43.1   \n",
              "..       ...            ...            ...      ...   ...   \n",
              "763    101.0           76.0           48.0    180.0  32.9   \n",
              "764    122.0           70.0           27.0    156.0  36.8   \n",
              "765    121.0           72.0           23.0    112.0  26.2   \n",
              "766    126.0           60.0           29.0    156.0  30.1   \n",
              "767     93.0           70.0           31.0    156.0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction   Age  \n",
              "0                       0.627  50.0  \n",
              "1                       0.351  31.0  \n",
              "2                       0.672  32.0  \n",
              "3                       0.167  21.0  \n",
              "4                       2.288  33.0  \n",
              "..                        ...   ...  \n",
              "763                     0.171  63.0  \n",
              "764                     0.340  27.0  \n",
              "765                     0.245  30.0  \n",
              "766                     0.349  47.0  \n",
              "767                     0.315  23.0  \n",
              "\n",
              "[768 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d3c0524-45b6-415c-86f0-98a1f6389de4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>183.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>89.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>101.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>122.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>121.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>126.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>93.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d3c0524-45b6-415c-86f0-98a1f6389de4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d3c0524-45b6-415c-86f0-98a1f6389de4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d3c0524-45b6-415c-86f0-98a1f6389de4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df['Pregnancies'] = diabetes.Pregnancies\n",
        "diabetes_df['Outcome'] = diabetes.Outcome"
      ],
      "metadata": {
        "id": "hT7ZbHJ4PXAc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "9FrKUgx8PpRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x = \"Outcome\", kind = \"count\", data = diabetes_df, palette = 'magma')\n",
        "\n",
        "# Output class is not balanced."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "L-B8zfPzPr1u",
        "outputId": "b1b7590c-acdf-4fe6-fcf3-41fed60241e0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7ff415377c90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imbalanced class\n",
        "diabetes_df['Outcome'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJJtPS_HQX-Q",
        "outputId": "a4f823e6-2a26-4053-c010-b045961a90a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    500\n",
              "1    268\n",
              "Name: Outcome, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Oversampling \n",
        "# Resample using \"bootstrapping\" method to generate samples by upsampling for each class\n",
        "from sklearn.utils import resample\n",
        "df_0 = diabetes_df[diabetes_df['Outcome'] == 0]\n",
        "df_1 = diabetes_df[diabetes_df['Outcome'] == 1]"
      ],
      "metadata": {
        "id": "FHJvaxLCRlom"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Resampling\n",
        "# Upsampling\n",
        "df_1_upsample = resample(df_1, n_samples = 500, replace = True, random_state = 123)"
      ],
      "metadata": {
        "id": "eDkEqpu4Rnvz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df1 = pd.concat([df_0, df_1_upsample])"
      ],
      "metadata": {
        "id": "iaUm-RjqRrkP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x = \"Outcome\", kind = \"count\", data = diabetes_df1, palette = 'magma')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "Qn0d1dhsRtbS",
        "outputId": "b27c33a0-e59b-4957-e82e-838ad552577a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7ff412625390>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQn0lEQVR4nO3de6zfdX3H8ecLKt6VW8ewLYHMqsGoSBqGc3842AXcZpkBolGp2KVLROMtccws2SUzUTNloJtZM5BCmIpXqjFspHjZHKhVkescFXW0AVquujncwPf+OJ/qEascSr/nfXr6fCQn5/v9fL+/33mXNM/8+Pb7+51UFZKk+bdf9wCStK8ywJLUxABLUhMDLElNDLAkNVnSPcCjcdJJJ9Xll1/ePYYkPZzsanGvfgV85513do8gSbttrw6wJO3NDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDWZNMBJvpPkuiTXJNk81g5OckWSm8f3g8Z6kpyXZEuSa5McO+VsktRtPl4B/0ZVHVNVq8b+2cCmqloJbBr7ACcDK8fXOuD98zCbJLXpuASxGtgwtjcAp8xav6hmXA0cmOTwhvkkaV5M/XGUBfxzkgL+vqrWA4dV1W3j+O3AYWN7GXDrrMduHWu3zVojyTpmXiFzxBFH7PZgr33OW3f7sVrY/u66d7X83G+/5U0tP1fz46h3n7PHn3PqAP96VW1L8kvAFUn+ffbBqqoR5zkbEV8PsGrVKn+ls6S91qSXIKpq2/i+HfgEcBxwx85LC+P79nH6NmDFrIcvH2uStChNFuAkT0zy5J3bwG8D1wMbgTXjtDXAZWN7I3DGuBvieOC+WZcqJGnRmfISxGHAJ5Ls/Dn/WFWXJ/kKcGmStcB3gdPH+Z8BXgxsAX4AnDnhbJLUbrIAV9UtwPN2sX4XcOIu1gs4a6p5JGmh8Z1wktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktRk8gAn2T/J15N8euwfleRLSbYk+XCSA8b6Y8f+lnH8yKlnk6RO8/EK+A3ATbP23wmcU1VPB+4B1o71tcA9Y/2ccZ4kLVqTBjjJcuB3gX8Y+wFOAD46TtkAnDK2V499xvETx/mStChN/Qr4b4C3Aj8a+4cA91bVA2N/K7BsbC8DbgUYx+8b50vSojRZgJP8HrC9qr66h593XZLNSTbv2LFjTz61JM2rKV8BvxB4SZLvAB9i5tLDucCBSZaMc5YD28b2NmAFwDj+VOCuhz5pVa2vqlVVtWrp0qUTji9J05oswFX1J1W1vKqOBF4GXFlVrwA+C5w6TlsDXDa2N459xvErq6qmmk+SunXcB/zHwJuTbGHmGu/5Y/184JCx/mbg7IbZJGneLHn4Ux69qvoc8LmxfQtw3C7OuR84bT7mkaSFwHfCSVITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTEAEtSEwMsSU0MsCQ1McCS1MQAS1ITAyxJTSYLcJLHJflykm8kuSHJX4z1o5J8KcmWJB9OcsBYf+zY3zKOHznVbJK0EEz5CviHwAlV9TzgGOCkJMcD7wTOqaqnA/cAa8f5a4F7xvo54zxJWrQmC3DN+K+x+5jxVcAJwEfH+gbglLG9euwzjp+YJFPNJ0ndJr0GnGT/JNcA24ErgG8B91bVA+OUrcCysb0MuBVgHL8POGQXz7kuyeYkm3fs2DHl+JI0qUkDXFUPVtUxwHLgOOBZe+A511fVqqpatXTp0kc9oyR1mZe7IKrqXuCzwAuAA5MsGYeWA9vG9jZgBcA4/lTgrvmYT5I6THkXxNIkB47txwO/BdzETIhPHaetAS4b2xvHPuP4lVVVU80nSd2WPPwpu+1wYEOS/ZkJ/aVV9ekkNwIfSvJXwNeB88f55wMXJ9kC3A28bMLZJKndZAGuqmuB5+9i/RZmrgc/dP1+4LSp5pGkhcZ3wklSEwMsSU0MsCQ1McCS1MQAS1KTOQU4yaa5rEmS5u4X3oaW5HHAE4BDkxwE7PxwnKfwk89wkCTthoe7D/iPgDcCTwO+yk8C/D3gfRPOJUmL3i8McFWdC5yb5PVV9d55mkmS9glzeidcVb03ya8BR85+TFVdNNFckrTozSnASS4GfgW4BnhwLBdggCVpN831syBWAUf76WSStOfM9T7g64FfnnIQSdrXzPUV8KHAjUm+zMwv2wSgql4yyVSStA+Ya4D/fMohJGlfNNe7ID4/9SCStK+Z610Q32fmrgeAA5j5FfP/XVVPmWowSVrs5voK+Mk7t5MEWA0cP9VQkrQveMSfhlYzPgn8zgTzSNI+Y66XIF46a3c/Zu4Lvn+SiSRpHzHXuyB+f9b2A8B3mLkMIUnaTXO9Bnzm1INI0r5mrh/IvjzJJ5JsH18fS7J86uEkaTGb6z/CfQDYyMznAj8N+NRYkyTtprkGeGlVfaCqHhhfFwJLJ5xLkha9uQb4riSvTLL/+HolcNeUg0nSYjfXAL8GOB24HbgNOBV49UQzSdI+Ya63of0lsKaq7gFIcjDw18yEWZK0G+b6Cvi5O+MLUFV3A8+fZiRJ2jfMNcD7jV9LD/z4FfBcXz1LknZhrhF9N3BVko+M/dOAt08zkiTtG+b6TriLkmwGThhLL62qG6cbS5IWvzlfRhjBNbqStIc84o+jlCTtGQZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqclkAU6yIslnk9yY5IYkbxjrBye5IsnN4/tBYz1JzkuyJcm1SY6dajZJWgimfAX8APCWqjoaOB44K8nRwNnApqpaCWwa+wAnAyvH1zrg/RPOJkntJgtwVd1WVV8b298HbgKWAauBDeO0DcApY3s1cFHNuBo4MMnhU80nSd3m5RpwkiOB5wNfAg6rqtvGoduBw8b2MuDWWQ/bOtYkaVGaPMBJngR8DHhjVX1v9rGqKqAe4fOtS7I5yeYdO3bswUklaX5NGuAkj2EmvpdU1cfH8h07Ly2M79vH+jZgxayHLx9rP6Wq1lfVqqpatXTp0umGl6SJTXkXRIDzgZuq6j2zDm0E1oztNcBls9bPGHdDHA/cN+tShSQtOksmfO4XAq8CrktyzVh7G/AO4NIka4HvAqePY58BXgxsAX4AnDnhbJLUbrIAV9W/Avk5h0/cxfkFnDXVPJK00PhOOElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqclkAU5yQZLtSa6ftXZwkiuS3Dy+HzTWk+S8JFuSXJvk2KnmkqSFYspXwBcCJz1k7WxgU1WtBDaNfYCTgZXjax3w/gnnkqQFYbIAV9UXgLsfsrwa2DC2NwCnzFq/qGZcDRyY5PCpZpOkhWC+rwEfVlW3je3bgcPG9jLg1lnnbR1rPyPJuiSbk2zesWPHdJNK0sTa/hGuqgqo3Xjc+qpaVVWrli5dOsFkkjQ/5jvAd+y8tDC+bx/r24AVs85bPtYkadGa7wBvBNaM7TXAZbPWzxh3QxwP3DfrUoUkLUpLpnriJB8EXgQcmmQr8GfAO4BLk6wFvgucPk7/DPBiYAvwA+DMqeaSpIVisgBX1ct/zqETd3FuAWdNNYskLUS+E06SmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWpigCWpiQGWpCYGWJKaGGBJamKAJamJAZakJgZYkpoYYElqYoAlqYkBlqQmBliSmhhgSWqyoAKc5KQk30yyJcnZ3fNI0pQWTICT7A/8LXAycDTw8iRH904lSdNZMAEGjgO2VNUtVfW/wIeA1c0zSdJkUlXdMwCQ5FTgpKr6w7H/KuBXq+p1DzlvHbBu7D4T+Oa8Drr3OhS4s3sILSr+nZq7O6vqpIcuLumY5NGoqvXA+u459jZJNlfVqu45tHj4d+rRW0iXILYBK2btLx9rkrQoLaQAfwVYmeSoJAcALwM2Ns8kSZNZMJcgquqBJK8D/gnYH7igqm5oHmsx8bKN9jT/Tj1KC+Yf4SRpX7OQLkFI0j7FAEtSEwO8yPn2bu1pSS5Isj3J9d2z7O0M8CLm27s1kQuBn3lTgR45A7y4+fZu7XFV9QXg7u45FgMDvLgtA26dtb91rElaAAywJDUxwIubb++WFjADvLj59m5pATPAi1hVPQDsfHv3TcClvr1bj1aSDwJXAc9MsjXJ2u6Z9la+FVmSmvgKWJKaGGBJamKAJamJAZakJgZYkpoYYO21kixPclmSm5N8K8m5437nX/SYt83XfNLDMcDaKyUJ8HHgk1W1EngG8CTg7Q/zUAOsBcMAa291AnB/VX0AoKoeBN4EvCbJa5O8b+eJST6d5EVJ3gE8Psk1SS4Zx85Icm2SbyS5eKwdmeTKsb4pyRFj/cIk709ydZJbxnNekOSmJBfO+nm/neSqJF9L8pEkT5q3/yraqxhg7a2eDXx19kJVfQ/4T37OL5utqrOB/6mqY6rqFUmeDfwpcEJVPQ94wzj1vcCGqnoucAlw3qynOQh4ATOx3wicM2Z5TpJjkhw6nvM3q+pYYDPw5j3xB9bis2B+K7LU4ATgI1V1J0BV7fyM2xcALx3bFwPvmvWYT1VVJbkOuKOqrgNIcgNwJDMfeHQ08MWZqyQcwMzbdqWfYYC1t7oROHX2QpKnAEcA9/LT/3f3uD34c384vv9o1vbO/SXAg8AVVfXyPfgztUh5CUJ7q03AE5KcAT/+9UvvZubX5dwCHJNkvyQrmPnNIDv9X5LHjO0rgdOSHDKe4+Cx/m/MfHIcwCuAf3kEc10NvDDJ08dzPjHJMx7pH077BgOsvVLNfIrUHzAT0JuB/wDuZ+Yuhy8C32bmVfJ5wNdmPXQ9cG2SS8Ynw70d+HySbwDvGee8HjgzybXAq/jJteG5zLUDeDXwwfH4q4Bn7e6fU4ubn4YmSU18BSxJTQywJDUxwJLUxABLUhMDLElNDLAkNTHAktTk/wHA4aUHXdiingAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train and Test"
      ],
      "metadata": {
        "id": "_nydhPY5StV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = diabetes_df1.drop(['Outcome'], axis = 1)\n",
        "Y = diabetes_df1['Outcome']"
      ],
      "metadata": {
        "id": "oPxqquhNSvmN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)"
      ],
      "metadata": {
        "id": "bFmUGmfOTR10"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANN Classification"
      ],
      "metadata": {
        "id": "feY8O1dFT-M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout is used to handle issue like overfitting.\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Optimizers\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "doZ4LoYqTjKe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  # Sequential Neural Network - FeedForward Neural Network\n",
        "  # Randomly have to choose the units value.\n",
        "  # We can give different combination of values for the units value. We can write a function and start a loop. At end we will know whcih \n",
        "  #combination of values are giving the best accuracy.\n",
        "\n",
        "  model = Sequential()\n",
        "  # Units = Num of Neurons (2 * pow(n)), input shape = Num of Features.\n",
        "  model.add(Dense(units = 64, activation = 'relu', input_shape = [len(X.keys())]))\n",
        "  \n",
        "  # Hidden layer - 1\n",
        "  model.add(Dense(units = 128, activation = 'relu'))\n",
        "\n",
        "  # Hidden layer - 2\n",
        "  model.add(Dense(units = 128, activation = 'relu'))\n",
        "\n",
        "  # Output Layer - For Classification\n",
        "  model.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "  # Optimizers\n",
        "  optimizers = Adam(learning_rate=0.001)\n",
        "\n",
        "  # Model Compiler\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = optimizers, metrics = ['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "  # Without Dropout"
      ],
      "metadata": {
        "id": "355QO5f2U0Zn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "HsWMMUMzVjyE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdYi4plAVmAw",
        "outputId": "a9df73b2-98bc-4679-cb1b-cf96d38a59cf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                576       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,537\n",
            "Trainable params: 25,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Epochs = Number of Iterations\n",
        "# epochs are choosen randomly. If accuracy is low, try increasing the epochs.\n",
        "# Batch size - no of samples per iteration.\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs = 500, batch_size = 25, validation_split = 0.15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8pmp8krWASg",
        "outputId": "c1057d7c-3ad2-495f-cbaa-4558a9f9d91e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "28/28 [==============================] - 1s 26ms/step - loss: 1.1647 - accuracy: 0.5926 - val_loss: 0.6329 - val_accuracy: 0.6750\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.7421 - accuracy: 0.6235 - val_loss: 0.6524 - val_accuracy: 0.6750\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6163 - accuracy: 0.6853 - val_loss: 0.6773 - val_accuracy: 0.6583\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.8001 - accuracy: 0.6279 - val_loss: 0.7431 - val_accuracy: 0.6583\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.7887 - accuracy: 0.6574 - val_loss: 0.6689 - val_accuracy: 0.6500\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.7489 - accuracy: 0.6750 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6468 - accuracy: 0.6750 - val_loss: 0.7707 - val_accuracy: 0.5833\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.6721 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.6073 - accuracy: 0.6912 - val_loss: 0.5578 - val_accuracy: 0.6917\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.6941 - val_loss: 0.6653 - val_accuracy: 0.6500\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.6079 - accuracy: 0.6956 - val_loss: 0.5314 - val_accuracy: 0.7417\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.5559 - accuracy: 0.7176 - val_loss: 0.5419 - val_accuracy: 0.7167\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.5453 - accuracy: 0.7309 - val_loss: 0.6180 - val_accuracy: 0.6917\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.7221 - val_loss: 0.4911 - val_accuracy: 0.7833\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.5729 - accuracy: 0.7147 - val_loss: 0.7171 - val_accuracy: 0.6833\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.5959 - accuracy: 0.7191 - val_loss: 0.5305 - val_accuracy: 0.7333\n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7441 - val_loss: 0.5674 - val_accuracy: 0.7083\n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.6000 - accuracy: 0.6882 - val_loss: 0.5409 - val_accuracy: 0.7083\n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.5246 - accuracy: 0.7412 - val_loss: 0.4887 - val_accuracy: 0.7583\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.5178 - accuracy: 0.7368 - val_loss: 0.5105 - val_accuracy: 0.7417\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.5781 - accuracy: 0.6985 - val_loss: 0.6427 - val_accuracy: 0.7083\n",
            "Epoch 22/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.5286 - accuracy: 0.7206 - val_loss: 0.5631 - val_accuracy: 0.7250\n",
            "Epoch 23/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.5300 - accuracy: 0.7353 - val_loss: 0.6166 - val_accuracy: 0.7167\n",
            "Epoch 24/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7338 - val_loss: 0.5633 - val_accuracy: 0.6917\n",
            "Epoch 25/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6446 - accuracy: 0.7162 - val_loss: 0.5097 - val_accuracy: 0.7333\n",
            "Epoch 26/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.6054 - accuracy: 0.7074 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
            "Epoch 27/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.5233 - accuracy: 0.7279 - val_loss: 0.5381 - val_accuracy: 0.7333\n",
            "Epoch 28/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.5217 - accuracy: 0.7500 - val_loss: 0.4724 - val_accuracy: 0.7667\n",
            "Epoch 29/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4791 - accuracy: 0.7544 - val_loss: 0.6210 - val_accuracy: 0.7083\n",
            "Epoch 30/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7529 - val_loss: 0.7249 - val_accuracy: 0.6833\n",
            "Epoch 31/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.5461 - accuracy: 0.7250 - val_loss: 0.5837 - val_accuracy: 0.7250\n",
            "Epoch 32/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7397 - val_loss: 0.6587 - val_accuracy: 0.7083\n",
            "Epoch 33/500\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.5042 - accuracy: 0.7324 - val_loss: 0.4901 - val_accuracy: 0.7417\n",
            "Epoch 34/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7662 - val_loss: 0.5599 - val_accuracy: 0.7083\n",
            "Epoch 35/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.4570 - accuracy: 0.7735 - val_loss: 0.4714 - val_accuracy: 0.7500\n",
            "Epoch 36/500\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.4603 - accuracy: 0.7794 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 37/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.7824 - val_loss: 0.4696 - val_accuracy: 0.7333\n",
            "Epoch 38/500\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.4688 - accuracy: 0.7588 - val_loss: 0.5476 - val_accuracy: 0.7667\n",
            "Epoch 39/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7618 - val_loss: 0.4656 - val_accuracy: 0.7833\n",
            "Epoch 40/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4822 - accuracy: 0.7588 - val_loss: 0.5074 - val_accuracy: 0.7583\n",
            "Epoch 41/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.8767 - accuracy: 0.6529 - val_loss: 0.6222 - val_accuracy: 0.7000\n",
            "Epoch 42/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.5119 - accuracy: 0.7515 - val_loss: 0.5022 - val_accuracy: 0.7333\n",
            "Epoch 43/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4823 - accuracy: 0.7544 - val_loss: 0.5040 - val_accuracy: 0.7333\n",
            "Epoch 44/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7426 - val_loss: 0.5276 - val_accuracy: 0.7083\n",
            "Epoch 45/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4998 - accuracy: 0.7309 - val_loss: 0.4828 - val_accuracy: 0.7583\n",
            "Epoch 46/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.4860 - accuracy: 0.7515 - val_loss: 0.4687 - val_accuracy: 0.7750\n",
            "Epoch 47/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7868 - val_loss: 0.5497 - val_accuracy: 0.7083\n",
            "Epoch 48/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4942 - accuracy: 0.7632 - val_loss: 0.4836 - val_accuracy: 0.8000\n",
            "Epoch 49/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.7750 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 50/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7667\n",
            "Epoch 51/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.7897 - val_loss: 0.4835 - val_accuracy: 0.7667\n",
            "Epoch 52/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.7824 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
            "Epoch 53/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.4878 - accuracy: 0.7662 - val_loss: 0.4741 - val_accuracy: 0.7667\n",
            "Epoch 54/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.7662 - val_loss: 0.4792 - val_accuracy: 0.7583\n",
            "Epoch 55/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7647 - val_loss: 0.6007 - val_accuracy: 0.7250\n",
            "Epoch 56/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.4664 - accuracy: 0.7662 - val_loss: 0.5080 - val_accuracy: 0.7333\n",
            "Epoch 57/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.7985 - val_loss: 0.4789 - val_accuracy: 0.7667\n",
            "Epoch 58/500\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.4054 - accuracy: 0.7971 - val_loss: 0.5360 - val_accuracy: 0.7333\n",
            "Epoch 59/500\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.4214 - accuracy: 0.7809 - val_loss: 0.4975 - val_accuracy: 0.7583\n",
            "Epoch 60/500\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.4143 - accuracy: 0.8044 - val_loss: 0.4906 - val_accuracy: 0.7667\n",
            "Epoch 61/500\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.4184 - accuracy: 0.7912 - val_loss: 0.5224 - val_accuracy: 0.7333\n",
            "Epoch 62/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.7794 - val_loss: 0.5905 - val_accuracy: 0.6833\n",
            "Epoch 63/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.7838 - val_loss: 0.5671 - val_accuracy: 0.7500\n",
            "Epoch 64/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.7912 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 65/500\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.4145 - accuracy: 0.7926 - val_loss: 0.4935 - val_accuracy: 0.7583\n",
            "Epoch 66/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.4013 - accuracy: 0.7985 - val_loss: 0.5207 - val_accuracy: 0.7417\n",
            "Epoch 67/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.7941 - val_loss: 0.5643 - val_accuracy: 0.7417\n",
            "Epoch 68/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.8088 - val_loss: 0.5195 - val_accuracy: 0.7333\n",
            "Epoch 69/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7676 - val_loss: 0.5939 - val_accuracy: 0.7333\n",
            "Epoch 70/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.7897 - val_loss: 0.5538 - val_accuracy: 0.7250\n",
            "Epoch 71/500\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.4085 - accuracy: 0.7971 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
            "Epoch 72/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.7971 - val_loss: 0.5247 - val_accuracy: 0.7417\n",
            "Epoch 73/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8074 - val_loss: 0.5791 - val_accuracy: 0.7250\n",
            "Epoch 74/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8029 - val_loss: 0.5898 - val_accuracy: 0.7417\n",
            "Epoch 75/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8059 - val_loss: 0.5085 - val_accuracy: 0.7417\n",
            "Epoch 76/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8015 - val_loss: 0.4930 - val_accuracy: 0.7667\n",
            "Epoch 77/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8103 - val_loss: 0.4797 - val_accuracy: 0.7667\n",
            "Epoch 78/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.3951 - accuracy: 0.8118 - val_loss: 0.5075 - val_accuracy: 0.7750\n",
            "Epoch 79/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8250 - val_loss: 0.4979 - val_accuracy: 0.8000\n",
            "Epoch 80/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.4067 - accuracy: 0.8191 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
            "Epoch 81/500\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.3852 - accuracy: 0.8103 - val_loss: 0.5011 - val_accuracy: 0.7750\n",
            "Epoch 82/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.3640 - accuracy: 0.8279 - val_loss: 0.4721 - val_accuracy: 0.7333\n",
            "Epoch 83/500\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.3706 - accuracy: 0.8368 - val_loss: 0.6389 - val_accuracy: 0.7333\n",
            "Epoch 84/500\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.3683 - accuracy: 0.8176 - val_loss: 0.5031 - val_accuracy: 0.7667\n",
            "Epoch 85/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.3522 - accuracy: 0.8265 - val_loss: 0.4530 - val_accuracy: 0.7833\n",
            "Epoch 86/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8235 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 87/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.7926 - val_loss: 0.4685 - val_accuracy: 0.7917\n",
            "Epoch 88/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8059 - val_loss: 0.4641 - val_accuracy: 0.7750\n",
            "Epoch 89/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8206 - val_loss: 0.4942 - val_accuracy: 0.7667\n",
            "Epoch 90/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8235 - val_loss: 0.4936 - val_accuracy: 0.7833\n",
            "Epoch 91/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8324 - val_loss: 0.5000 - val_accuracy: 0.7917\n",
            "Epoch 92/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8441 - val_loss: 0.6538 - val_accuracy: 0.6833\n",
            "Epoch 93/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8221 - val_loss: 0.4956 - val_accuracy: 0.7833\n",
            "Epoch 94/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8294 - val_loss: 0.5034 - val_accuracy: 0.7750\n",
            "Epoch 95/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8500 - val_loss: 0.5364 - val_accuracy: 0.7333\n",
            "Epoch 96/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8441 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 97/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8603 - val_loss: 0.4983 - val_accuracy: 0.7917\n",
            "Epoch 98/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8441 - val_loss: 0.5310 - val_accuracy: 0.7917\n",
            "Epoch 99/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8456 - val_loss: 0.5204 - val_accuracy: 0.7417\n",
            "Epoch 100/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8412 - val_loss: 0.5156 - val_accuracy: 0.8000\n",
            "Epoch 101/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8691 - val_loss: 0.5148 - val_accuracy: 0.7750\n",
            "Epoch 102/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.8515 - val_loss: 0.4427 - val_accuracy: 0.7917\n",
            "Epoch 103/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8618 - val_loss: 0.5830 - val_accuracy: 0.7917\n",
            "Epoch 104/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8426 - val_loss: 0.4759 - val_accuracy: 0.7750\n",
            "Epoch 105/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8618 - val_loss: 0.5277 - val_accuracy: 0.7667\n",
            "Epoch 106/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8750 - val_loss: 0.4463 - val_accuracy: 0.7917\n",
            "Epoch 107/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3098 - accuracy: 0.8632 - val_loss: 0.4963 - val_accuracy: 0.8167\n",
            "Epoch 108/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8471 - val_loss: 0.4810 - val_accuracy: 0.8167\n",
            "Epoch 109/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3226 - accuracy: 0.8618 - val_loss: 0.5252 - val_accuracy: 0.7833\n",
            "Epoch 110/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8603 - val_loss: 0.4630 - val_accuracy: 0.8000\n",
            "Epoch 111/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.8721 - val_loss: 0.4512 - val_accuracy: 0.8083\n",
            "Epoch 112/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8794 - val_loss: 0.5177 - val_accuracy: 0.7917\n",
            "Epoch 113/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.8765 - val_loss: 0.4976 - val_accuracy: 0.7750\n",
            "Epoch 114/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8324 - val_loss: 0.5208 - val_accuracy: 0.7750\n",
            "Epoch 115/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8441 - val_loss: 0.4698 - val_accuracy: 0.7583\n",
            "Epoch 116/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8456 - val_loss: 0.5187 - val_accuracy: 0.7667\n",
            "Epoch 117/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8662 - val_loss: 0.4725 - val_accuracy: 0.8083\n",
            "Epoch 118/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8485 - val_loss: 0.6370 - val_accuracy: 0.7583\n",
            "Epoch 119/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.8603 - val_loss: 0.5328 - val_accuracy: 0.7417\n",
            "Epoch 120/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8574 - val_loss: 0.5291 - val_accuracy: 0.7583\n",
            "Epoch 121/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8559 - val_loss: 0.4881 - val_accuracy: 0.8167\n",
            "Epoch 122/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.8824 - val_loss: 0.4969 - val_accuracy: 0.7917\n",
            "Epoch 123/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.8765 - val_loss: 0.6113 - val_accuracy: 0.7167\n",
            "Epoch 124/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8647 - val_loss: 0.5706 - val_accuracy: 0.7500\n",
            "Epoch 125/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.8662 - val_loss: 0.5103 - val_accuracy: 0.7917\n",
            "Epoch 126/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.8779 - val_loss: 0.5431 - val_accuracy: 0.8083\n",
            "Epoch 127/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.8868 - val_loss: 0.5375 - val_accuracy: 0.8083\n",
            "Epoch 128/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2524 - accuracy: 0.8971 - val_loss: 0.5228 - val_accuracy: 0.7917\n",
            "Epoch 129/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.8985 - val_loss: 0.5087 - val_accuracy: 0.7917\n",
            "Epoch 130/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.8868 - val_loss: 0.5059 - val_accuracy: 0.7833\n",
            "Epoch 131/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2462 - accuracy: 0.9118 - val_loss: 0.6206 - val_accuracy: 0.7333\n",
            "Epoch 132/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2643 - accuracy: 0.8897 - val_loss: 0.4866 - val_accuracy: 0.7917\n",
            "Epoch 133/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2350 - accuracy: 0.9029 - val_loss: 0.5521 - val_accuracy: 0.8000\n",
            "Epoch 134/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2409 - accuracy: 0.9015 - val_loss: 0.5681 - val_accuracy: 0.8167\n",
            "Epoch 135/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8926 - val_loss: 0.6145 - val_accuracy: 0.7167\n",
            "Epoch 136/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2270 - accuracy: 0.9103 - val_loss: 0.4898 - val_accuracy: 0.8083\n",
            "Epoch 137/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2304 - accuracy: 0.9015 - val_loss: 0.5400 - val_accuracy: 0.8250\n",
            "Epoch 138/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9118 - val_loss: 0.4920 - val_accuracy: 0.7917\n",
            "Epoch 139/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2140 - accuracy: 0.9132 - val_loss: 0.5656 - val_accuracy: 0.8083\n",
            "Epoch 140/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.9029 - val_loss: 0.5005 - val_accuracy: 0.8250\n",
            "Epoch 141/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2171 - accuracy: 0.9074 - val_loss: 0.5387 - val_accuracy: 0.7833\n",
            "Epoch 142/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.8853 - val_loss: 0.5909 - val_accuracy: 0.7917\n",
            "Epoch 143/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.9147 - val_loss: 0.5660 - val_accuracy: 0.8167\n",
            "Epoch 144/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2577 - accuracy: 0.9015 - val_loss: 0.5036 - val_accuracy: 0.7833\n",
            "Epoch 145/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9044 - val_loss: 0.5174 - val_accuracy: 0.8333\n",
            "Epoch 146/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2252 - accuracy: 0.8956 - val_loss: 0.5545 - val_accuracy: 0.8417\n",
            "Epoch 147/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2299 - accuracy: 0.9015 - val_loss: 0.5207 - val_accuracy: 0.8167\n",
            "Epoch 148/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9147 - val_loss: 0.4693 - val_accuracy: 0.8083\n",
            "Epoch 149/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9176 - val_loss: 0.5798 - val_accuracy: 0.7833\n",
            "Epoch 150/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9206 - val_loss: 0.5265 - val_accuracy: 0.8250\n",
            "Epoch 151/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9176 - val_loss: 0.5457 - val_accuracy: 0.8167\n",
            "Epoch 152/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9132 - val_loss: 0.5046 - val_accuracy: 0.8000\n",
            "Epoch 153/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2491 - accuracy: 0.8882 - val_loss: 0.4942 - val_accuracy: 0.8250\n",
            "Epoch 154/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.9176 - val_loss: 0.5511 - val_accuracy: 0.8333\n",
            "Epoch 155/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1848 - accuracy: 0.9206 - val_loss: 0.6346 - val_accuracy: 0.8083\n",
            "Epoch 156/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1839 - accuracy: 0.9235 - val_loss: 0.5928 - val_accuracy: 0.7917\n",
            "Epoch 157/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9162 - val_loss: 0.6732 - val_accuracy: 0.8083\n",
            "Epoch 158/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2357 - accuracy: 0.8971 - val_loss: 0.6374 - val_accuracy: 0.8083\n",
            "Epoch 159/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2172 - accuracy: 0.9132 - val_loss: 0.6116 - val_accuracy: 0.8250\n",
            "Epoch 160/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1710 - accuracy: 0.9324 - val_loss: 0.6352 - val_accuracy: 0.8000\n",
            "Epoch 161/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9353 - val_loss: 0.6046 - val_accuracy: 0.8000\n",
            "Epoch 162/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1694 - accuracy: 0.9338 - val_loss: 0.5285 - val_accuracy: 0.8333\n",
            "Epoch 163/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9191 - val_loss: 0.5838 - val_accuracy: 0.7750\n",
            "Epoch 164/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9294 - val_loss: 0.6048 - val_accuracy: 0.8083\n",
            "Epoch 165/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9368 - val_loss: 0.6350 - val_accuracy: 0.8083\n",
            "Epoch 166/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.9426 - val_loss: 0.6287 - val_accuracy: 0.8333\n",
            "Epoch 167/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9559 - val_loss: 0.6681 - val_accuracy: 0.8000\n",
            "Epoch 168/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9544 - val_loss: 0.6919 - val_accuracy: 0.8000\n",
            "Epoch 169/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9397 - val_loss: 0.6644 - val_accuracy: 0.8000\n",
            "Epoch 170/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9441 - val_loss: 0.5884 - val_accuracy: 0.8333\n",
            "Epoch 171/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9412 - val_loss: 0.6233 - val_accuracy: 0.8083\n",
            "Epoch 172/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9426 - val_loss: 0.5903 - val_accuracy: 0.8083\n",
            "Epoch 173/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9426 - val_loss: 0.5699 - val_accuracy: 0.8083\n",
            "Epoch 174/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1813 - accuracy: 0.9235 - val_loss: 0.5239 - val_accuracy: 0.8000\n",
            "Epoch 175/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9500 - val_loss: 0.7250 - val_accuracy: 0.7667\n",
            "Epoch 176/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2122 - accuracy: 0.9441 - val_loss: 0.8401 - val_accuracy: 0.7167\n",
            "Epoch 177/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1765 - accuracy: 0.9382 - val_loss: 0.6455 - val_accuracy: 0.8250\n",
            "Epoch 178/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9250 - val_loss: 0.5500 - val_accuracy: 0.8417\n",
            "Epoch 179/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.9471 - val_loss: 0.5265 - val_accuracy: 0.8250\n",
            "Epoch 180/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9529 - val_loss: 0.7668 - val_accuracy: 0.8083\n",
            "Epoch 181/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9441 - val_loss: 0.5878 - val_accuracy: 0.8250\n",
            "Epoch 182/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9529 - val_loss: 0.6789 - val_accuracy: 0.8167\n",
            "Epoch 183/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9515 - val_loss: 0.6156 - val_accuracy: 0.8250\n",
            "Epoch 184/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9485 - val_loss: 0.6167 - val_accuracy: 0.8250\n",
            "Epoch 185/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1539 - accuracy: 0.9279 - val_loss: 0.6206 - val_accuracy: 0.8250\n",
            "Epoch 186/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1247 - accuracy: 0.9559 - val_loss: 0.6868 - val_accuracy: 0.7750\n",
            "Epoch 187/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9603 - val_loss: 0.6180 - val_accuracy: 0.8500\n",
            "Epoch 188/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1152 - accuracy: 0.9662 - val_loss: 0.7034 - val_accuracy: 0.8167\n",
            "Epoch 189/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9529 - val_loss: 0.7414 - val_accuracy: 0.8333\n",
            "Epoch 190/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9441 - val_loss: 0.7535 - val_accuracy: 0.7833\n",
            "Epoch 191/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9544 - val_loss: 0.6714 - val_accuracy: 0.8167\n",
            "Epoch 192/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9426 - val_loss: 0.6652 - val_accuracy: 0.7750\n",
            "Epoch 193/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9544 - val_loss: 0.7102 - val_accuracy: 0.7917\n",
            "Epoch 194/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9603 - val_loss: 0.7421 - val_accuracy: 0.7583\n",
            "Epoch 195/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9588 - val_loss: 0.6785 - val_accuracy: 0.8000\n",
            "Epoch 196/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9618 - val_loss: 0.7216 - val_accuracy: 0.8333\n",
            "Epoch 197/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1572 - accuracy: 0.9309 - val_loss: 0.8461 - val_accuracy: 0.7917\n",
            "Epoch 198/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1164 - accuracy: 0.9588 - val_loss: 0.6205 - val_accuracy: 0.8250\n",
            "Epoch 199/500\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.0860 - accuracy: 0.9721 - val_loss: 0.6461 - val_accuracy: 0.8000\n",
            "Epoch 200/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.0856 - accuracy: 0.9750 - val_loss: 0.7608 - val_accuracy: 0.7417\n",
            "Epoch 201/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.1256 - accuracy: 0.9485 - val_loss: 0.8069 - val_accuracy: 0.8083\n",
            "Epoch 202/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9691 - val_loss: 0.6432 - val_accuracy: 0.8167\n",
            "Epoch 203/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9485 - val_loss: 0.8200 - val_accuracy: 0.8000\n",
            "Epoch 204/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8765 - val_loss: 0.6668 - val_accuracy: 0.7667\n",
            "Epoch 205/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.3811 - accuracy: 0.8691 - val_loss: 0.5982 - val_accuracy: 0.8083\n",
            "Epoch 206/500\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.2283 - accuracy: 0.9206 - val_loss: 0.5480 - val_accuracy: 0.8500\n",
            "Epoch 207/500\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.1961 - accuracy: 0.9382 - val_loss: 0.5548 - val_accuracy: 0.8417\n",
            "Epoch 208/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9441 - val_loss: 0.6372 - val_accuracy: 0.8083\n",
            "Epoch 209/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9838 - val_loss: 0.7030 - val_accuracy: 0.8167\n",
            "Epoch 210/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9779 - val_loss: 0.6555 - val_accuracy: 0.8250\n",
            "Epoch 211/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9809 - val_loss: 0.6657 - val_accuracy: 0.8250\n",
            "Epoch 212/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.0687 - accuracy: 0.9824 - val_loss: 0.6829 - val_accuracy: 0.8417\n",
            "Epoch 213/500\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.0804 - accuracy: 0.9735 - val_loss: 0.6465 - val_accuracy: 0.8250\n",
            "Epoch 214/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0863 - accuracy: 0.9662 - val_loss: 0.7925 - val_accuracy: 0.7833\n",
            "Epoch 215/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9779 - val_loss: 0.6987 - val_accuracy: 0.8167\n",
            "Epoch 216/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9853 - val_loss: 0.6791 - val_accuracy: 0.8083\n",
            "Epoch 217/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9853 - val_loss: 0.7334 - val_accuracy: 0.8250\n",
            "Epoch 218/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9926 - val_loss: 0.6974 - val_accuracy: 0.8500\n",
            "Epoch 219/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9676 - val_loss: 0.6503 - val_accuracy: 0.8333\n",
            "Epoch 220/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9838 - val_loss: 0.7057 - val_accuracy: 0.8250\n",
            "Epoch 221/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 0.9926 - val_loss: 0.7160 - val_accuracy: 0.8083\n",
            "Epoch 222/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.7616 - val_accuracy: 0.8333\n",
            "Epoch 223/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0538 - accuracy: 0.9882 - val_loss: 0.6649 - val_accuracy: 0.8583\n",
            "Epoch 224/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9750 - val_loss: 0.6813 - val_accuracy: 0.7917\n",
            "Epoch 225/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9338 - val_loss: 0.8440 - val_accuracy: 0.7917\n",
            "Epoch 226/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9397 - val_loss: 0.7756 - val_accuracy: 0.8417\n",
            "Epoch 227/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9515 - val_loss: 0.7420 - val_accuracy: 0.8250\n",
            "Epoch 228/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9618 - val_loss: 0.7224 - val_accuracy: 0.7917\n",
            "Epoch 229/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9662 - val_loss: 0.8104 - val_accuracy: 0.8000\n",
            "Epoch 230/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9603 - val_loss: 0.7686 - val_accuracy: 0.7667\n",
            "Epoch 231/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9662 - val_loss: 0.7573 - val_accuracy: 0.8250\n",
            "Epoch 232/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9574 - val_loss: 0.6722 - val_accuracy: 0.8333\n",
            "Epoch 233/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9618 - val_loss: 0.7050 - val_accuracy: 0.8333\n",
            "Epoch 234/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1140 - accuracy: 0.9500 - val_loss: 0.6751 - val_accuracy: 0.7833\n",
            "Epoch 235/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9691 - val_loss: 0.6350 - val_accuracy: 0.8333\n",
            "Epoch 236/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9676 - val_loss: 0.7529 - val_accuracy: 0.8500\n",
            "Epoch 237/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9824 - val_loss: 0.7586 - val_accuracy: 0.8167\n",
            "Epoch 238/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9926 - val_loss: 0.7861 - val_accuracy: 0.8333\n",
            "Epoch 239/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9912 - val_loss: 0.7648 - val_accuracy: 0.8417\n",
            "Epoch 240/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9809 - val_loss: 0.7915 - val_accuracy: 0.8333\n",
            "Epoch 241/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9779 - val_loss: 0.7407 - val_accuracy: 0.8417\n",
            "Epoch 242/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9897 - val_loss: 0.7937 - val_accuracy: 0.8500\n",
            "Epoch 243/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9926 - val_loss: 0.8133 - val_accuracy: 0.8500\n",
            "Epoch 244/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9912 - val_loss: 0.7970 - val_accuracy: 0.8167\n",
            "Epoch 245/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9824 - val_loss: 0.7990 - val_accuracy: 0.8250\n",
            "Epoch 246/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9868 - val_loss: 0.8666 - val_accuracy: 0.7833\n",
            "Epoch 247/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9941 - val_loss: 0.7697 - val_accuracy: 0.8500\n",
            "Epoch 248/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9926 - val_loss: 0.8548 - val_accuracy: 0.8333\n",
            "Epoch 249/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.8246 - val_accuracy: 0.8417\n",
            "Epoch 250/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9926 - val_loss: 0.8456 - val_accuracy: 0.8250\n",
            "Epoch 251/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9956 - val_loss: 0.8365 - val_accuracy: 0.8500\n",
            "Epoch 252/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9971 - val_loss: 0.8817 - val_accuracy: 0.8167\n",
            "Epoch 253/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9882 - val_loss: 0.8852 - val_accuracy: 0.8167\n",
            "Epoch 254/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 0.8624 - val_accuracy: 0.8000\n",
            "Epoch 255/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9824 - val_loss: 0.8961 - val_accuracy: 0.8167\n",
            "Epoch 256/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9897 - val_loss: 0.8075 - val_accuracy: 0.8167\n",
            "Epoch 257/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9941 - val_loss: 0.7734 - val_accuracy: 0.8417\n",
            "Epoch 258/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9926 - val_loss: 0.7913 - val_accuracy: 0.8333\n",
            "Epoch 259/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9868 - val_loss: 0.7674 - val_accuracy: 0.8250\n",
            "Epoch 260/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9941 - val_loss: 0.7991 - val_accuracy: 0.8500\n",
            "Epoch 261/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9897 - val_loss: 0.8570 - val_accuracy: 0.8750\n",
            "Epoch 262/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9721 - val_loss: 0.8841 - val_accuracy: 0.8083\n",
            "Epoch 263/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.9426 - val_loss: 0.9558 - val_accuracy: 0.7250\n",
            "Epoch 264/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8985 - val_loss: 1.2174 - val_accuracy: 0.7083\n",
            "Epoch 265/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8794 - val_loss: 0.7826 - val_accuracy: 0.8000\n",
            "Epoch 266/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.8824 - val_loss: 0.7617 - val_accuracy: 0.7333\n",
            "Epoch 267/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2284 - accuracy: 0.9029 - val_loss: 0.6359 - val_accuracy: 0.7833\n",
            "Epoch 268/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1371 - accuracy: 0.9397 - val_loss: 0.5709 - val_accuracy: 0.8333\n",
            "Epoch 269/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9779 - val_loss: 0.5998 - val_accuracy: 0.8333\n",
            "Epoch 270/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9897 - val_loss: 0.6524 - val_accuracy: 0.8500\n",
            "Epoch 271/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9926 - val_loss: 0.6185 - val_accuracy: 0.8333\n",
            "Epoch 272/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9941 - val_loss: 0.6546 - val_accuracy: 0.8417\n",
            "Epoch 273/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9956 - val_loss: 0.6934 - val_accuracy: 0.8417\n",
            "Epoch 274/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9985 - val_loss: 0.7114 - val_accuracy: 0.8333\n",
            "Epoch 275/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0262 - accuracy: 0.9971 - val_loss: 0.7162 - val_accuracy: 0.8417\n",
            "Epoch 276/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9985 - val_loss: 0.7400 - val_accuracy: 0.8167\n",
            "Epoch 277/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9956 - val_loss: 0.7138 - val_accuracy: 0.8417\n",
            "Epoch 278/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9882 - val_loss: 0.9598 - val_accuracy: 0.8000\n",
            "Epoch 279/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9838 - val_loss: 0.7972 - val_accuracy: 0.8167\n",
            "Epoch 280/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9897 - val_loss: 0.7475 - val_accuracy: 0.8250\n",
            "Epoch 281/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9735 - val_loss: 0.8044 - val_accuracy: 0.8417\n",
            "Epoch 282/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9882 - val_loss: 0.7417 - val_accuracy: 0.8500\n",
            "Epoch 283/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9941 - val_loss: 0.7955 - val_accuracy: 0.8583\n",
            "Epoch 284/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0253 - accuracy: 0.9985 - val_loss: 0.8316 - val_accuracy: 0.8417\n",
            "Epoch 285/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9971 - val_loss: 0.8261 - val_accuracy: 0.8500\n",
            "Epoch 286/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.8250\n",
            "Epoch 287/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9956 - val_loss: 0.8352 - val_accuracy: 0.8167\n",
            "Epoch 288/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 0.8195 - val_accuracy: 0.8250\n",
            "Epoch 289/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9956 - val_loss: 0.8315 - val_accuracy: 0.8500\n",
            "Epoch 290/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9985 - val_loss: 0.8804 - val_accuracy: 0.8167\n",
            "Epoch 291/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9971 - val_loss: 0.8447 - val_accuracy: 0.8500\n",
            "Epoch 292/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9882 - val_loss: 0.9445 - val_accuracy: 0.8083\n",
            "Epoch 293/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9559 - val_loss: 0.9229 - val_accuracy: 0.8000\n",
            "Epoch 294/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9221 - val_loss: 1.4332 - val_accuracy: 0.7417\n",
            "Epoch 295/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2028 - accuracy: 0.9191 - val_loss: 0.7153 - val_accuracy: 0.7917\n",
            "Epoch 296/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9824 - val_loss: 0.7352 - val_accuracy: 0.8417\n",
            "Epoch 297/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9765 - val_loss: 0.7710 - val_accuracy: 0.8417\n",
            "Epoch 298/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.9794 - val_loss: 0.8110 - val_accuracy: 0.8083\n",
            "Epoch 299/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9897 - val_loss: 0.8751 - val_accuracy: 0.7917\n",
            "Epoch 300/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 0.8031 - val_accuracy: 0.8167\n",
            "Epoch 301/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9956 - val_loss: 0.8191 - val_accuracy: 0.8250\n",
            "Epoch 302/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9985 - val_loss: 0.8175 - val_accuracy: 0.8250\n",
            "Epoch 303/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9985 - val_loss: 0.8608 - val_accuracy: 0.8250\n",
            "Epoch 304/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9985 - val_loss: 0.8496 - val_accuracy: 0.8500\n",
            "Epoch 305/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9985 - val_loss: 0.8223 - val_accuracy: 0.8333\n",
            "Epoch 306/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9985 - val_loss: 0.8266 - val_accuracy: 0.8333\n",
            "Epoch 307/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 0.9985 - val_loss: 0.8206 - val_accuracy: 0.8333\n",
            "Epoch 308/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9985 - val_loss: 0.8349 - val_accuracy: 0.8333\n",
            "Epoch 309/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.8288 - val_accuracy: 0.8417\n",
            "Epoch 310/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.7863 - val_accuracy: 0.8417\n",
            "Epoch 311/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9956 - val_loss: 0.8265 - val_accuracy: 0.8500\n",
            "Epoch 312/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.8431 - val_accuracy: 0.8417\n",
            "Epoch 313/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9971 - val_loss: 0.8314 - val_accuracy: 0.8167\n",
            "Epoch 314/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.8659 - val_accuracy: 0.8500\n",
            "Epoch 315/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.8956 - val_accuracy: 0.8333\n",
            "Epoch 316/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.8663 - val_accuracy: 0.8333\n",
            "Epoch 317/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.8804 - val_accuracy: 0.8417\n",
            "Epoch 318/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9985 - val_loss: 0.8818 - val_accuracy: 0.8417\n",
            "Epoch 319/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.8691 - val_accuracy: 0.8417\n",
            "Epoch 320/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.8745 - val_accuracy: 0.8667\n",
            "Epoch 321/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 0.9048 - val_accuracy: 0.8167\n",
            "Epoch 322/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9809 - val_loss: 0.9418 - val_accuracy: 0.7917\n",
            "Epoch 323/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9926 - val_loss: 0.8505 - val_accuracy: 0.8667\n",
            "Epoch 324/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.8723 - val_accuracy: 0.8417\n",
            "Epoch 325/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1596 - accuracy: 0.9632 - val_loss: 1.1593 - val_accuracy: 0.8250\n",
            "Epoch 326/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8691 - val_loss: 0.8903 - val_accuracy: 0.7833\n",
            "Epoch 327/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8912 - val_loss: 0.8206 - val_accuracy: 0.8333\n",
            "Epoch 328/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9309 - val_loss: 0.8587 - val_accuracy: 0.8083\n",
            "Epoch 329/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1983 - accuracy: 0.9235 - val_loss: 0.8545 - val_accuracy: 0.8250\n",
            "Epoch 330/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9588 - val_loss: 0.9049 - val_accuracy: 0.7917\n",
            "Epoch 331/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9882 - val_loss: 0.8975 - val_accuracy: 0.8333\n",
            "Epoch 332/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9941 - val_loss: 0.9008 - val_accuracy: 0.8333\n",
            "Epoch 333/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.8851 - val_accuracy: 0.8583\n",
            "Epoch 334/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.9099 - val_accuracy: 0.8500\n",
            "Epoch 335/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.8583\n",
            "Epoch 336/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9985 - val_loss: 0.9161 - val_accuracy: 0.8583\n",
            "Epoch 337/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9971 - val_loss: 0.9947 - val_accuracy: 0.8583\n",
            "Epoch 338/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9956 - val_loss: 0.9662 - val_accuracy: 0.8500\n",
            "Epoch 339/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.8500\n",
            "Epoch 340/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9897 - val_loss: 1.0401 - val_accuracy: 0.8083\n",
            "Epoch 341/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9956 - val_loss: 0.9720 - val_accuracy: 0.8500\n",
            "Epoch 342/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.9525 - val_accuracy: 0.8583\n",
            "Epoch 343/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.9716 - val_accuracy: 0.8500\n",
            "Epoch 344/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9985 - val_loss: 0.9649 - val_accuracy: 0.8500\n",
            "Epoch 345/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.8500\n",
            "Epoch 346/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.0008 - val_accuracy: 0.8500\n",
            "Epoch 347/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 1.0286 - val_accuracy: 0.8500\n",
            "Epoch 348/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.0042 - val_accuracy: 0.8583\n",
            "Epoch 349/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.0076 - val_accuracy: 0.8500\n",
            "Epoch 350/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.0447 - val_accuracy: 0.8500\n",
            "Epoch 351/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 1.0268 - val_accuracy: 0.8417\n",
            "Epoch 352/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9941 - val_loss: 1.0069 - val_accuracy: 0.8500\n",
            "Epoch 353/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9971 - val_loss: 1.0532 - val_accuracy: 0.8583\n",
            "Epoch 354/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 1.0484 - val_accuracy: 0.8417\n",
            "Epoch 355/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 0.8583\n",
            "Epoch 356/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 1.0675 - val_accuracy: 0.8583\n",
            "Epoch 357/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9941 - val_loss: 1.0845 - val_accuracy: 0.8250\n",
            "Epoch 358/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9471 - val_loss: 0.6880 - val_accuracy: 0.8500\n",
            "Epoch 359/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9426 - val_loss: 1.0825 - val_accuracy: 0.8000\n",
            "Epoch 360/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9765 - val_loss: 0.8837 - val_accuracy: 0.8583\n",
            "Epoch 361/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9868 - val_loss: 0.9040 - val_accuracy: 0.8667\n",
            "Epoch 362/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9809 - val_loss: 1.0911 - val_accuracy: 0.8167\n",
            "Epoch 363/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9838 - val_loss: 1.0042 - val_accuracy: 0.8333\n",
            "Epoch 364/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9868 - val_loss: 1.0061 - val_accuracy: 0.8250\n",
            "Epoch 365/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9941 - val_loss: 0.9948 - val_accuracy: 0.8417\n",
            "Epoch 366/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9956 - val_loss: 0.9997 - val_accuracy: 0.8417\n",
            "Epoch 367/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9838 - val_loss: 0.9357 - val_accuracy: 0.8500\n",
            "Epoch 368/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9765 - val_loss: 1.2447 - val_accuracy: 0.8000\n",
            "Epoch 369/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2431 - accuracy: 0.9250 - val_loss: 0.8798 - val_accuracy: 0.7917\n",
            "Epoch 370/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9368 - val_loss: 0.9791 - val_accuracy: 0.8167\n",
            "Epoch 371/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.9118 - val_loss: 0.7799 - val_accuracy: 0.7833\n",
            "Epoch 372/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.9162 - val_loss: 0.5916 - val_accuracy: 0.8083\n",
            "Epoch 373/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2704 - accuracy: 0.9074 - val_loss: 0.6926 - val_accuracy: 0.8250\n",
            "Epoch 374/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9441 - val_loss: 0.7444 - val_accuracy: 0.8417\n",
            "Epoch 375/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.9926 - val_loss: 0.7532 - val_accuracy: 0.8333\n",
            "Epoch 376/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.8174 - val_accuracy: 0.8417\n",
            "Epoch 377/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.8333\n",
            "Epoch 378/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.8272 - val_accuracy: 0.8417\n",
            "Epoch 379/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.8378 - val_accuracy: 0.8417\n",
            "Epoch 380/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.8250\n",
            "Epoch 381/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.8487 - val_accuracy: 0.8417\n",
            "Epoch 382/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.8562 - val_accuracy: 0.8417\n",
            "Epoch 383/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.9041 - val_accuracy: 0.8250\n",
            "Epoch 384/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.8820 - val_accuracy: 0.8333\n",
            "Epoch 385/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.8723 - val_accuracy: 0.8667\n",
            "Epoch 386/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8845 - val_accuracy: 0.8583\n",
            "Epoch 387/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.9100 - val_accuracy: 0.8417\n",
            "Epoch 388/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.8417\n",
            "Epoch 389/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.8812 - val_accuracy: 0.8667\n",
            "Epoch 390/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9017 - val_accuracy: 0.8583\n",
            "Epoch 391/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.9019 - val_accuracy: 0.8417\n",
            "Epoch 392/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.9202 - val_accuracy: 0.8500\n",
            "Epoch 393/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9173 - val_accuracy: 0.8583\n",
            "Epoch 394/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.9383 - val_accuracy: 0.8417\n",
            "Epoch 395/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9412 - val_accuracy: 0.8583\n",
            "Epoch 396/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9352 - val_accuracy: 0.8583\n",
            "Epoch 397/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9299 - val_accuracy: 0.8583\n",
            "Epoch 398/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.8583\n",
            "Epoch 399/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9461 - val_accuracy: 0.8583\n",
            "Epoch 400/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.8500\n",
            "Epoch 401/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.8417\n",
            "Epoch 402/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9545 - val_accuracy: 0.8500\n",
            "Epoch 403/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9644 - val_accuracy: 0.8583\n",
            "Epoch 404/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9711 - val_accuracy: 0.8500\n",
            "Epoch 405/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.9830 - val_accuracy: 0.8500\n",
            "Epoch 406/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.8417\n",
            "Epoch 407/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 1.0116 - val_accuracy: 0.8417\n",
            "Epoch 408/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9769 - val_accuracy: 0.8500\n",
            "Epoch 409/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9999 - val_accuracy: 0.8500\n",
            "Epoch 410/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0137 - val_accuracy: 0.8333\n",
            "Epoch 411/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0164 - val_accuracy: 0.8500\n",
            "Epoch 412/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.8500\n",
            "Epoch 413/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0252 - val_accuracy: 0.8417\n",
            "Epoch 414/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.0320 - val_accuracy: 0.8333\n",
            "Epoch 415/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0108 - val_accuracy: 0.8583\n",
            "Epoch 416/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0249 - val_accuracy: 0.8583\n",
            "Epoch 417/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0314 - val_accuracy: 0.8583\n",
            "Epoch 418/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0366 - val_accuracy: 0.8417\n",
            "Epoch 419/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 1.0328 - val_accuracy: 0.8250\n",
            "Epoch 420/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 1.0286 - val_accuracy: 0.8000\n",
            "Epoch 421/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9632 - val_loss: 1.0826 - val_accuracy: 0.8250\n",
            "Epoch 422/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9735 - val_loss: 1.0433 - val_accuracy: 0.8333\n",
            "Epoch 423/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9588 - val_loss: 1.0137 - val_accuracy: 0.7833\n",
            "Epoch 424/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9618 - val_loss: 1.1628 - val_accuracy: 0.8417\n",
            "Epoch 425/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.9235 - val_loss: 1.0753 - val_accuracy: 0.7333\n",
            "Epoch 426/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.9015 - val_loss: 0.7910 - val_accuracy: 0.8333\n",
            "Epoch 427/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.9118 - val_loss: 0.8761 - val_accuracy: 0.8250\n",
            "Epoch 428/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.9176 - val_loss: 0.7061 - val_accuracy: 0.8167\n",
            "Epoch 429/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2158 - accuracy: 0.9294 - val_loss: 0.8394 - val_accuracy: 0.7667\n",
            "Epoch 430/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.9647 - val_loss: 0.8357 - val_accuracy: 0.8083\n",
            "Epoch 431/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9794 - val_loss: 0.7885 - val_accuracy: 0.8333\n",
            "Epoch 432/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9956 - val_loss: 0.7959 - val_accuracy: 0.8333\n",
            "Epoch 433/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.8142 - val_accuracy: 0.8417\n",
            "Epoch 434/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.8274 - val_accuracy: 0.8417\n",
            "Epoch 435/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 0.8516 - val_accuracy: 0.8417\n",
            "Epoch 436/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.8651 - val_accuracy: 0.8417\n",
            "Epoch 437/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.8737 - val_accuracy: 0.8417\n",
            "Epoch 438/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.8686 - val_accuracy: 0.8500\n",
            "Epoch 439/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.8826 - val_accuracy: 0.8417\n",
            "Epoch 440/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.8965 - val_accuracy: 0.8417\n",
            "Epoch 441/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9008 - val_accuracy: 0.8417\n",
            "Epoch 442/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9304 - val_accuracy: 0.8417\n",
            "Epoch 443/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.8500\n",
            "Epoch 444/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.9315 - val_accuracy: 0.8417\n",
            "Epoch 445/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9422 - val_accuracy: 0.8417\n",
            "Epoch 446/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9418 - val_accuracy: 0.8417\n",
            "Epoch 447/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9479 - val_accuracy: 0.8417\n",
            "Epoch 448/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9381 - val_accuracy: 0.8583\n",
            "Epoch 449/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.8417\n",
            "Epoch 450/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9522 - val_accuracy: 0.8500\n",
            "Epoch 451/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.8333\n",
            "Epoch 452/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.9691 - val_accuracy: 0.8583\n",
            "Epoch 453/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9766 - val_accuracy: 0.8500\n",
            "Epoch 454/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9779 - val_accuracy: 0.8500\n",
            "Epoch 455/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9815 - val_accuracy: 0.8500\n",
            "Epoch 456/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.8583\n",
            "Epoch 457/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9786 - val_accuracy: 0.8583\n",
            "Epoch 458/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9735 - val_accuracy: 0.8500\n",
            "Epoch 459/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.8583\n",
            "Epoch 460/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 0.8583\n",
            "Epoch 461/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0041 - val_accuracy: 0.8500\n",
            "Epoch 462/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9995 - val_accuracy: 0.8583\n",
            "Epoch 463/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0232 - val_accuracy: 0.8500\n",
            "Epoch 464/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.8500\n",
            "Epoch 465/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0284 - val_accuracy: 0.8500\n",
            "Epoch 466/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0286 - val_accuracy: 0.8500\n",
            "Epoch 467/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.8583\n",
            "Epoch 468/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.0428 - val_accuracy: 0.8500\n",
            "Epoch 469/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0482 - val_accuracy: 0.8333\n",
            "Epoch 470/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0317 - val_accuracy: 0.8583\n",
            "Epoch 471/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0346 - val_accuracy: 0.8583\n",
            "Epoch 472/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0242 - val_accuracy: 0.8583\n",
            "Epoch 473/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0406 - val_accuracy: 0.8583\n",
            "Epoch 474/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0576 - val_accuracy: 0.8583\n",
            "Epoch 475/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0569 - val_accuracy: 0.8583\n",
            "Epoch 476/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0623 - val_accuracy: 0.8583\n",
            "Epoch 477/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0616 - val_accuracy: 0.8583\n",
            "Epoch 478/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0681 - val_accuracy: 0.8583\n",
            "Epoch 479/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0762 - val_accuracy: 0.8583\n",
            "Epoch 480/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9912 - val_loss: 1.0960 - val_accuracy: 0.8417\n",
            "Epoch 481/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1280 - accuracy: 0.9706 - val_loss: 1.0292 - val_accuracy: 0.7750\n",
            "Epoch 482/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.9088 - val_loss: 1.3265 - val_accuracy: 0.8000\n",
            "Epoch 483/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 0.9294 - val_loss: 0.7430 - val_accuracy: 0.8417\n",
            "Epoch 484/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1240 - accuracy: 0.9559 - val_loss: 1.0963 - val_accuracy: 0.8250\n",
            "Epoch 485/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1286 - accuracy: 0.9456 - val_loss: 0.9248 - val_accuracy: 0.8167\n",
            "Epoch 486/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.9147 - val_loss: 0.8969 - val_accuracy: 0.7833\n",
            "Epoch 487/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1418 - accuracy: 0.9515 - val_loss: 0.9612 - val_accuracy: 0.7833\n",
            "Epoch 488/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9750 - val_loss: 0.8346 - val_accuracy: 0.8000\n",
            "Epoch 489/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9397 - val_loss: 0.8042 - val_accuracy: 0.8333\n",
            "Epoch 490/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9853 - val_loss: 0.9904 - val_accuracy: 0.8167\n",
            "Epoch 491/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9897 - val_loss: 0.9929 - val_accuracy: 0.8417\n",
            "Epoch 492/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.9758 - val_accuracy: 0.8167\n",
            "Epoch 493/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.9690 - val_accuracy: 0.8167\n",
            "Epoch 494/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.8250\n",
            "Epoch 495/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9904 - val_accuracy: 0.8250\n",
            "Epoch 496/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0001 - val_accuracy: 0.8167\n",
            "Epoch 497/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.8250\n",
            "Epoch 498/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 0.8250\n",
            "Epoch 499/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.8250\n",
            "Epoch 500/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0171 - val_accuracy: 0.8333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot(figsize = (7,6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "1h9T8yD9XRHc",
        "outputId": "b790f651-d58c-4dd1-cae2-5ffa01f7e659"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff3a5f30e10>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy is 1 for training and less than 80 for test samples. This is Overfitting.\n",
        "# We want to use some techniques to overcome overfitting\n",
        "# Technique :1 - Using Dropout."
      ],
      "metadata": {
        "id": "x8wl-H5XX_iI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With Dropout\n",
        "\n",
        "def build_model():\n",
        "  # Sequential Neural Network - FeedForward Neural Network\n",
        "  # Randomly have to choose the units value.\n",
        "  # We can give different combination of values for the units value. We can write a function and start a loop. At end we will know whcih \n",
        "  #combination of values are giving the best accuracy.\n",
        "\n",
        "  model = Sequential()\n",
        "  # Units = Num of Neurons (2 * pow(n)), input shape = Num of Features.\n",
        "  model.add(Dense(units = 64, activation = 'relu', input_shape = [len(X.keys())]))\n",
        "  model.add(Dropout(0.2))\n",
        "  \n",
        "  # Hidden layer - 1\n",
        "  model.add(Dense(units = 128, activation = 'relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Hidden layer - 2\n",
        "  model.add(Dense(units = 128, activation = 'relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Output Layer - For Classification\n",
        "  model.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "  # Optimizers\n",
        "  optimizers = Adam(learning_rate=0.001)\n",
        "\n",
        "  # Model Compiler\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = optimizers, metrics = ['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "siyYvCbOYm31"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "xo_w-MpuZ3aU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7JFFzIMZ88C",
        "outputId": "e58a3287-41f0-4c0d-a8cb-0ba2d4fb8ef8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 64)                576       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,537\n",
            "Trainable params: 25,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Epochs = Number of Iterations\n",
        "# batch_size = number of samples per iteration\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs = 500, batch_size = 25, validation_split=0.15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfRjHaB-aCMG",
        "outputId": "b083f323-7ae7-4c29-bc1d-eb306a28d4f9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 4.2778 - accuracy: 0.5691 - val_loss: 1.0616 - val_accuracy: 0.5917\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 2.7948 - accuracy: 0.5544 - val_loss: 0.9276 - val_accuracy: 0.5750\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1.5766 - accuracy: 0.5544 - val_loss: 0.5900 - val_accuracy: 0.6583\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1.4765 - accuracy: 0.5412 - val_loss: 0.6441 - val_accuracy: 0.6250\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1.3571 - accuracy: 0.5456 - val_loss: 0.6362 - val_accuracy: 0.6333\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.9693 - accuracy: 0.5897 - val_loss: 0.5543 - val_accuracy: 0.6333\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.9371 - accuracy: 0.6118 - val_loss: 0.5776 - val_accuracy: 0.6417\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8926 - accuracy: 0.5676 - val_loss: 0.6036 - val_accuracy: 0.6333\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.8286 - accuracy: 0.5882 - val_loss: 0.6051 - val_accuracy: 0.6500\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.8465 - accuracy: 0.5603 - val_loss: 0.6272 - val_accuracy: 0.6167\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7374 - accuracy: 0.6029 - val_loss: 0.5827 - val_accuracy: 0.6833\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7686 - accuracy: 0.5853 - val_loss: 0.5958 - val_accuracy: 0.6917\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.7455 - accuracy: 0.5853 - val_loss: 0.5886 - val_accuracy: 0.7000\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7580 - accuracy: 0.6074 - val_loss: 0.5973 - val_accuracy: 0.6750\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.5824 - val_loss: 0.6143 - val_accuracy: 0.6667\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.7301 - accuracy: 0.5971 - val_loss: 0.5838 - val_accuracy: 0.6917\n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.6191 - val_loss: 0.5787 - val_accuracy: 0.6917\n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.6162 - val_loss: 0.6133 - val_accuracy: 0.6917\n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.6176 - val_loss: 0.5721 - val_accuracy: 0.7333\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.6412 - val_loss: 0.5601 - val_accuracy: 0.7167\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.6382 - val_loss: 0.5976 - val_accuracy: 0.7167\n",
            "Epoch 22/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6338 - val_loss: 0.5747 - val_accuracy: 0.6917\n",
            "Epoch 23/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6397 - val_loss: 0.5556 - val_accuracy: 0.6917\n",
            "Epoch 24/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.6250 - val_loss: 0.5835 - val_accuracy: 0.7167\n",
            "Epoch 25/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6632 - val_loss: 0.5720 - val_accuracy: 0.7167\n",
            "Epoch 26/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.6529 - val_loss: 0.5622 - val_accuracy: 0.7083\n",
            "Epoch 27/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6485 - val_loss: 0.5771 - val_accuracy: 0.7167\n",
            "Epoch 28/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6588 - val_loss: 0.5760 - val_accuracy: 0.7083\n",
            "Epoch 29/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.6485 - val_loss: 0.5920 - val_accuracy: 0.7000\n",
            "Epoch 30/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.6882 - val_loss: 0.5794 - val_accuracy: 0.7167\n",
            "Epoch 31/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6868 - val_loss: 0.5800 - val_accuracy: 0.7167\n",
            "Epoch 32/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.6353 - val_loss: 0.5773 - val_accuracy: 0.7167\n",
            "Epoch 33/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.6735 - val_loss: 0.5599 - val_accuracy: 0.7250\n",
            "Epoch 34/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6809 - val_loss: 0.5565 - val_accuracy: 0.7250\n",
            "Epoch 35/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6735 - val_loss: 0.5746 - val_accuracy: 0.7083\n",
            "Epoch 36/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6691 - val_loss: 0.5649 - val_accuracy: 0.7083\n",
            "Epoch 37/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.6397 - val_loss: 0.5807 - val_accuracy: 0.7333\n",
            "Epoch 38/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.6809 - val_loss: 0.5473 - val_accuracy: 0.6833\n",
            "Epoch 39/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.6691 - val_loss: 0.5344 - val_accuracy: 0.7083\n",
            "Epoch 40/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.6426 - val_loss: 0.5477 - val_accuracy: 0.6833\n",
            "Epoch 41/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6897 - val_loss: 0.5654 - val_accuracy: 0.7333\n",
            "Epoch 42/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.6735 - val_loss: 0.5475 - val_accuracy: 0.7333\n",
            "Epoch 43/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.6824 - val_loss: 0.5530 - val_accuracy: 0.7167\n",
            "Epoch 44/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.7044 - val_loss: 0.5309 - val_accuracy: 0.7333\n",
            "Epoch 45/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.6765 - val_loss: 0.5435 - val_accuracy: 0.7750\n",
            "Epoch 46/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.6809 - val_loss: 0.5437 - val_accuracy: 0.7167\n",
            "Epoch 47/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.6721 - val_loss: 0.5501 - val_accuracy: 0.7750\n",
            "Epoch 48/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.6794 - val_loss: 0.5407 - val_accuracy: 0.7417\n",
            "Epoch 49/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6750 - val_loss: 0.5352 - val_accuracy: 0.7333\n",
            "Epoch 50/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.6912 - val_loss: 0.5535 - val_accuracy: 0.7333\n",
            "Epoch 51/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7074 - val_loss: 0.5260 - val_accuracy: 0.7417\n",
            "Epoch 52/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.6897 - val_loss: 0.5210 - val_accuracy: 0.7000\n",
            "Epoch 53/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6794 - val_loss: 0.5449 - val_accuracy: 0.7333\n",
            "Epoch 54/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.6985 - val_loss: 0.5136 - val_accuracy: 0.7167\n",
            "Epoch 55/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7015 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 56/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7029 - val_loss: 0.5169 - val_accuracy: 0.7250\n",
            "Epoch 57/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.7000 - val_loss: 0.5115 - val_accuracy: 0.7667\n",
            "Epoch 58/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7103 - val_loss: 0.5164 - val_accuracy: 0.7583\n",
            "Epoch 59/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.6926 - val_loss: 0.5219 - val_accuracy: 0.7167\n",
            "Epoch 60/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7074 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
            "Epoch 61/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6809 - val_loss: 0.5541 - val_accuracy: 0.7417\n",
            "Epoch 62/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.6765 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
            "Epoch 63/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7015 - val_loss: 0.5163 - val_accuracy: 0.7417\n",
            "Epoch 64/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.7015 - val_loss: 0.5252 - val_accuracy: 0.7417\n",
            "Epoch 65/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7029 - val_loss: 0.5320 - val_accuracy: 0.7250\n",
            "Epoch 66/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7074 - val_loss: 0.5212 - val_accuracy: 0.7583\n",
            "Epoch 67/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7191 - val_loss: 0.5193 - val_accuracy: 0.7750\n",
            "Epoch 68/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.6956 - val_loss: 0.5013 - val_accuracy: 0.7000\n",
            "Epoch 69/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7294 - val_loss: 0.5169 - val_accuracy: 0.7333\n",
            "Epoch 70/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7265 - val_loss: 0.5294 - val_accuracy: 0.7583\n",
            "Epoch 71/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7162 - val_loss: 0.5051 - val_accuracy: 0.7750\n",
            "Epoch 72/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7059 - val_loss: 0.5240 - val_accuracy: 0.7667\n",
            "Epoch 73/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7132 - val_loss: 0.5143 - val_accuracy: 0.7333\n",
            "Epoch 74/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7059 - val_loss: 0.5123 - val_accuracy: 0.7667\n",
            "Epoch 75/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7221 - val_loss: 0.5103 - val_accuracy: 0.7583\n",
            "Epoch 76/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.6985 - val_loss: 0.4979 - val_accuracy: 0.7667\n",
            "Epoch 77/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7029 - val_loss: 0.4870 - val_accuracy: 0.7750\n",
            "Epoch 78/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7176 - val_loss: 0.4904 - val_accuracy: 0.7667\n",
            "Epoch 79/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7162 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
            "Epoch 80/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7250 - val_loss: 0.4985 - val_accuracy: 0.7167\n",
            "Epoch 81/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7132 - val_loss: 0.4920 - val_accuracy: 0.7250\n",
            "Epoch 82/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7088 - val_loss: 0.5220 - val_accuracy: 0.7667\n",
            "Epoch 83/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7309 - val_loss: 0.4895 - val_accuracy: 0.7417\n",
            "Epoch 84/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7324 - val_loss: 0.4923 - val_accuracy: 0.7417\n",
            "Epoch 85/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7412 - val_loss: 0.5070 - val_accuracy: 0.7583\n",
            "Epoch 86/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7265 - val_loss: 0.4917 - val_accuracy: 0.7750\n",
            "Epoch 87/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7221 - val_loss: 0.5050 - val_accuracy: 0.7750\n",
            "Epoch 88/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7324 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
            "Epoch 89/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7250 - val_loss: 0.5046 - val_accuracy: 0.7750\n",
            "Epoch 90/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7265 - val_loss: 0.5101 - val_accuracy: 0.7583\n",
            "Epoch 91/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7471 - val_loss: 0.4894 - val_accuracy: 0.7917\n",
            "Epoch 92/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7353 - val_loss: 0.5045 - val_accuracy: 0.7250\n",
            "Epoch 93/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7279 - val_loss: 0.5130 - val_accuracy: 0.7250\n",
            "Epoch 94/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7338 - val_loss: 0.4812 - val_accuracy: 0.7750\n",
            "Epoch 95/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7250 - val_loss: 0.4838 - val_accuracy: 0.7917\n",
            "Epoch 96/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7515 - val_loss: 0.4917 - val_accuracy: 0.8000\n",
            "Epoch 97/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7309 - val_loss: 0.4944 - val_accuracy: 0.7750\n",
            "Epoch 98/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7485 - val_loss: 0.4895 - val_accuracy: 0.7417\n",
            "Epoch 99/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7250 - val_loss: 0.4936 - val_accuracy: 0.7917\n",
            "Epoch 100/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7485 - val_loss: 0.5075 - val_accuracy: 0.7833\n",
            "Epoch 101/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7309 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
            "Epoch 102/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7500 - val_loss: 0.5237 - val_accuracy: 0.7083\n",
            "Epoch 103/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7456 - val_loss: 0.4919 - val_accuracy: 0.7583\n",
            "Epoch 104/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7456 - val_loss: 0.4846 - val_accuracy: 0.7833\n",
            "Epoch 105/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7441 - val_loss: 0.5156 - val_accuracy: 0.7583\n",
            "Epoch 106/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7544 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
            "Epoch 107/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7588 - val_loss: 0.4835 - val_accuracy: 0.7833\n",
            "Epoch 108/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7471 - val_loss: 0.4780 - val_accuracy: 0.7917\n",
            "Epoch 109/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7235 - val_loss: 0.4885 - val_accuracy: 0.7750\n",
            "Epoch 110/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7544 - val_loss: 0.4769 - val_accuracy: 0.7833\n",
            "Epoch 111/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7382 - val_loss: 0.4923 - val_accuracy: 0.7667\n",
            "Epoch 112/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7368 - val_loss: 0.4905 - val_accuracy: 0.7750\n",
            "Epoch 113/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7441 - val_loss: 0.4736 - val_accuracy: 0.7667\n",
            "Epoch 114/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7426 - val_loss: 0.5050 - val_accuracy: 0.7667\n",
            "Epoch 115/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7324 - val_loss: 0.5190 - val_accuracy: 0.7583\n",
            "Epoch 116/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7353 - val_loss: 0.4880 - val_accuracy: 0.7917\n",
            "Epoch 117/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7485 - val_loss: 0.4834 - val_accuracy: 0.7833\n",
            "Epoch 118/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7353 - val_loss: 0.4599 - val_accuracy: 0.7750\n",
            "Epoch 119/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7603 - val_loss: 0.4732 - val_accuracy: 0.7833\n",
            "Epoch 120/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7471 - val_loss: 0.4843 - val_accuracy: 0.7833\n",
            "Epoch 121/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7574 - val_loss: 0.4944 - val_accuracy: 0.7667\n",
            "Epoch 122/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7529 - val_loss: 0.4773 - val_accuracy: 0.7917\n",
            "Epoch 123/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7632 - val_loss: 0.4783 - val_accuracy: 0.7750\n",
            "Epoch 124/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7500 - val_loss: 0.4752 - val_accuracy: 0.8083\n",
            "Epoch 125/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7588 - val_loss: 0.5094 - val_accuracy: 0.7250\n",
            "Epoch 126/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7691 - val_loss: 0.4770 - val_accuracy: 0.7833\n",
            "Epoch 127/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7691 - val_loss: 0.4802 - val_accuracy: 0.7583\n",
            "Epoch 128/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7603 - val_loss: 0.4748 - val_accuracy: 0.8083\n",
            "Epoch 129/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7544 - val_loss: 0.4831 - val_accuracy: 0.7667\n",
            "Epoch 130/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7544 - val_loss: 0.4716 - val_accuracy: 0.8000\n",
            "Epoch 131/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7691 - val_loss: 0.4616 - val_accuracy: 0.8083\n",
            "Epoch 132/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7500 - val_loss: 0.4863 - val_accuracy: 0.7750\n",
            "Epoch 133/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7632 - val_loss: 0.4967 - val_accuracy: 0.7583\n",
            "Epoch 134/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7529 - val_loss: 0.4858 - val_accuracy: 0.8083\n",
            "Epoch 135/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7471 - val_loss: 0.4841 - val_accuracy: 0.7667\n",
            "Epoch 136/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7676 - val_loss: 0.4830 - val_accuracy: 0.7917\n",
            "Epoch 137/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7515 - val_loss: 0.4691 - val_accuracy: 0.7917\n",
            "Epoch 138/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7559 - val_loss: 0.4571 - val_accuracy: 0.7917\n",
            "Epoch 139/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7706 - val_loss: 0.4866 - val_accuracy: 0.7750\n",
            "Epoch 140/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7485 - val_loss: 0.4740 - val_accuracy: 0.8167\n",
            "Epoch 141/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7588 - val_loss: 0.4759 - val_accuracy: 0.8000\n",
            "Epoch 142/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7794 - val_loss: 0.4599 - val_accuracy: 0.8167\n",
            "Epoch 143/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7882 - val_loss: 0.4844 - val_accuracy: 0.7750\n",
            "Epoch 144/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7706 - val_loss: 0.4950 - val_accuracy: 0.7833\n",
            "Epoch 145/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7544 - val_loss: 0.4716 - val_accuracy: 0.7500\n",
            "Epoch 146/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7676 - val_loss: 0.4762 - val_accuracy: 0.7417\n",
            "Epoch 147/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7544 - val_loss: 0.4642 - val_accuracy: 0.7667\n",
            "Epoch 148/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7647 - val_loss: 0.4761 - val_accuracy: 0.7917\n",
            "Epoch 149/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7735 - val_loss: 0.4843 - val_accuracy: 0.7833\n",
            "Epoch 150/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7794 - val_loss: 0.4694 - val_accuracy: 0.7750\n",
            "Epoch 151/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7735 - val_loss: 0.4853 - val_accuracy: 0.7917\n",
            "Epoch 152/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7574 - val_loss: 0.4703 - val_accuracy: 0.7750\n",
            "Epoch 153/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7632 - val_loss: 0.4876 - val_accuracy: 0.7750\n",
            "Epoch 154/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7794 - val_loss: 0.4935 - val_accuracy: 0.7833\n",
            "Epoch 155/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7500 - val_loss: 0.4686 - val_accuracy: 0.7917\n",
            "Epoch 156/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7618 - val_loss: 0.4783 - val_accuracy: 0.7833\n",
            "Epoch 157/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7779 - val_loss: 0.4667 - val_accuracy: 0.8083\n",
            "Epoch 158/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7662 - val_loss: 0.5028 - val_accuracy: 0.7750\n",
            "Epoch 159/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7735 - val_loss: 0.4872 - val_accuracy: 0.7750\n",
            "Epoch 160/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7779 - val_loss: 0.4733 - val_accuracy: 0.7583\n",
            "Epoch 161/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7897 - val_loss: 0.4692 - val_accuracy: 0.7583\n",
            "Epoch 162/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7750 - val_loss: 0.4893 - val_accuracy: 0.7667\n",
            "Epoch 163/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7662 - val_loss: 0.4499 - val_accuracy: 0.8000\n",
            "Epoch 164/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7735 - val_loss: 0.4768 - val_accuracy: 0.7667\n",
            "Epoch 165/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7809 - val_loss: 0.4772 - val_accuracy: 0.7833\n",
            "Epoch 166/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7838 - val_loss: 0.4675 - val_accuracy: 0.7583\n",
            "Epoch 167/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7794 - val_loss: 0.4657 - val_accuracy: 0.8167\n",
            "Epoch 168/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7618 - val_loss: 0.4993 - val_accuracy: 0.7333\n",
            "Epoch 169/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7765 - val_loss: 0.4837 - val_accuracy: 0.7500\n",
            "Epoch 170/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.8015 - val_loss: 0.4652 - val_accuracy: 0.8000\n",
            "Epoch 171/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7809 - val_loss: 0.4711 - val_accuracy: 0.7833\n",
            "Epoch 172/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7794 - val_loss: 0.4688 - val_accuracy: 0.7500\n",
            "Epoch 173/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7603 - val_loss: 0.4917 - val_accuracy: 0.7667\n",
            "Epoch 174/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7706 - val_loss: 0.4725 - val_accuracy: 0.7833\n",
            "Epoch 175/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7809 - val_loss: 0.5029 - val_accuracy: 0.7417\n",
            "Epoch 176/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7971 - val_loss: 0.4833 - val_accuracy: 0.7667\n",
            "Epoch 177/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7853 - val_loss: 0.4812 - val_accuracy: 0.7750\n",
            "Epoch 178/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7691 - val_loss: 0.4801 - val_accuracy: 0.7917\n",
            "Epoch 179/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7765 - val_loss: 0.4594 - val_accuracy: 0.7833\n",
            "Epoch 180/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7333\n",
            "Epoch 181/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7912 - val_loss: 0.4727 - val_accuracy: 0.7500\n",
            "Epoch 182/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7985 - val_loss: 0.4918 - val_accuracy: 0.7417\n",
            "Epoch 183/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7721 - val_loss: 0.5133 - val_accuracy: 0.7333\n",
            "Epoch 184/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7779 - val_loss: 0.4963 - val_accuracy: 0.7583\n",
            "Epoch 185/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7838 - val_loss: 0.4855 - val_accuracy: 0.7583\n",
            "Epoch 186/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7794 - val_loss: 0.4805 - val_accuracy: 0.7500\n",
            "Epoch 187/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7853 - val_loss: 0.4822 - val_accuracy: 0.7833\n",
            "Epoch 188/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7912 - val_loss: 0.5025 - val_accuracy: 0.7500\n",
            "Epoch 189/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7897 - val_loss: 0.4974 - val_accuracy: 0.7583\n",
            "Epoch 190/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7794 - val_loss: 0.4623 - val_accuracy: 0.8000\n",
            "Epoch 191/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7794 - val_loss: 0.5026 - val_accuracy: 0.7833\n",
            "Epoch 192/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7853 - val_loss: 0.5044 - val_accuracy: 0.8000\n",
            "Epoch 193/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7985 - val_loss: 0.5358 - val_accuracy: 0.7667\n",
            "Epoch 194/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7956 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
            "Epoch 195/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7779 - val_loss: 0.5075 - val_accuracy: 0.7583\n",
            "Epoch 196/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7853 - val_loss: 0.4918 - val_accuracy: 0.7667\n",
            "Epoch 197/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7667\n",
            "Epoch 198/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7912 - val_loss: 0.5384 - val_accuracy: 0.7667\n",
            "Epoch 199/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7912 - val_loss: 0.5158 - val_accuracy: 0.7667\n",
            "Epoch 200/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8074 - val_loss: 0.4656 - val_accuracy: 0.7500\n",
            "Epoch 201/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7926 - val_loss: 0.4747 - val_accuracy: 0.7750\n",
            "Epoch 202/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7779 - val_loss: 0.5028 - val_accuracy: 0.7667\n",
            "Epoch 203/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7882 - val_loss: 0.4620 - val_accuracy: 0.7333\n",
            "Epoch 204/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7868 - val_loss: 0.4980 - val_accuracy: 0.7417\n",
            "Epoch 205/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8059 - val_loss: 0.4857 - val_accuracy: 0.7583\n",
            "Epoch 206/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7956 - val_loss: 0.5142 - val_accuracy: 0.7417\n",
            "Epoch 207/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8044 - val_loss: 0.5005 - val_accuracy: 0.7667\n",
            "Epoch 208/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5125 - val_accuracy: 0.7583\n",
            "Epoch 209/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7956 - val_loss: 0.4984 - val_accuracy: 0.7417\n",
            "Epoch 210/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8000 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
            "Epoch 211/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8103 - val_loss: 0.5143 - val_accuracy: 0.7833\n",
            "Epoch 212/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7853 - val_loss: 0.4614 - val_accuracy: 0.7833\n",
            "Epoch 213/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7529 - val_loss: 0.5012 - val_accuracy: 0.7667\n",
            "Epoch 214/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8132 - val_loss: 0.4863 - val_accuracy: 0.7750\n",
            "Epoch 215/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7941 - val_loss: 0.4761 - val_accuracy: 0.7750\n",
            "Epoch 216/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7912 - val_loss: 0.4735 - val_accuracy: 0.7250\n",
            "Epoch 217/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7941 - val_loss: 0.4871 - val_accuracy: 0.7667\n",
            "Epoch 218/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7971 - val_loss: 0.4761 - val_accuracy: 0.7667\n",
            "Epoch 219/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8044 - val_loss: 0.4861 - val_accuracy: 0.7583\n",
            "Epoch 220/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7750 - val_loss: 0.4918 - val_accuracy: 0.7583\n",
            "Epoch 221/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7985 - val_loss: 0.4630 - val_accuracy: 0.8167\n",
            "Epoch 222/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7603 - val_loss: 0.4965 - val_accuracy: 0.7833\n",
            "Epoch 223/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8044 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
            "Epoch 224/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.7971 - val_loss: 0.4560 - val_accuracy: 0.7667\n",
            "Epoch 225/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7868 - val_loss: 0.5076 - val_accuracy: 0.7750\n",
            "Epoch 226/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.7971 - val_loss: 0.5040 - val_accuracy: 0.7417\n",
            "Epoch 227/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8294 - val_loss: 0.5376 - val_accuracy: 0.7500\n",
            "Epoch 228/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7926 - val_loss: 0.5440 - val_accuracy: 0.7750\n",
            "Epoch 229/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8265 - val_loss: 0.4910 - val_accuracy: 0.8000\n",
            "Epoch 230/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8132 - val_loss: 0.5164 - val_accuracy: 0.7750\n",
            "Epoch 231/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8088 - val_loss: 0.5007 - val_accuracy: 0.7833\n",
            "Epoch 232/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.8147 - val_loss: 0.5363 - val_accuracy: 0.7833\n",
            "Epoch 233/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.7971 - val_loss: 0.5200 - val_accuracy: 0.7667\n",
            "Epoch 234/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.7956 - val_loss: 0.5266 - val_accuracy: 0.7750\n",
            "Epoch 235/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8132 - val_loss: 0.5337 - val_accuracy: 0.7917\n",
            "Epoch 236/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.8059 - val_loss: 0.4877 - val_accuracy: 0.8167\n",
            "Epoch 237/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8132 - val_loss: 0.4955 - val_accuracy: 0.7833\n",
            "Epoch 238/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8059 - val_loss: 0.5163 - val_accuracy: 0.7833\n",
            "Epoch 239/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.7985 - val_loss: 0.4844 - val_accuracy: 0.7667\n",
            "Epoch 240/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7853 - val_loss: 0.4531 - val_accuracy: 0.7833\n",
            "Epoch 241/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8206 - val_loss: 0.4638 - val_accuracy: 0.7917\n",
            "Epoch 242/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8176 - val_loss: 0.5678 - val_accuracy: 0.7833\n",
            "Epoch 243/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7926 - val_loss: 0.5509 - val_accuracy: 0.7667\n",
            "Epoch 244/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8000 - val_loss: 0.5108 - val_accuracy: 0.7667\n",
            "Epoch 245/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8103 - val_loss: 0.4790 - val_accuracy: 0.8000\n",
            "Epoch 246/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8206 - val_loss: 0.5078 - val_accuracy: 0.7583\n",
            "Epoch 247/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8059 - val_loss: 0.5162 - val_accuracy: 0.7583\n",
            "Epoch 248/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8191 - val_loss: 0.5572 - val_accuracy: 0.7667\n",
            "Epoch 249/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7618 - val_loss: 0.5144 - val_accuracy: 0.7750\n",
            "Epoch 250/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7824 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
            "Epoch 251/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8162 - val_loss: 0.5204 - val_accuracy: 0.7667\n",
            "Epoch 252/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7985 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
            "Epoch 253/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8250 - val_loss: 0.4932 - val_accuracy: 0.7917\n",
            "Epoch 254/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8132 - val_loss: 0.4784 - val_accuracy: 0.7500\n",
            "Epoch 255/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8015 - val_loss: 0.5305 - val_accuracy: 0.7583\n",
            "Epoch 256/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7941 - val_loss: 0.4877 - val_accuracy: 0.7583\n",
            "Epoch 257/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8118 - val_loss: 0.4829 - val_accuracy: 0.7917\n",
            "Epoch 258/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3922 - accuracy: 0.8132 - val_loss: 0.5392 - val_accuracy: 0.7833\n",
            "Epoch 259/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8044 - val_loss: 0.4974 - val_accuracy: 0.7833\n",
            "Epoch 260/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8279 - val_loss: 0.5088 - val_accuracy: 0.7750\n",
            "Epoch 261/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8368 - val_loss: 0.5102 - val_accuracy: 0.7750\n",
            "Epoch 262/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3901 - accuracy: 0.8088 - val_loss: 0.4659 - val_accuracy: 0.8167\n",
            "Epoch 263/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.8162 - val_loss: 0.5461 - val_accuracy: 0.8000\n",
            "Epoch 264/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8132 - val_loss: 0.5110 - val_accuracy: 0.7583\n",
            "Epoch 265/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8221 - val_loss: 0.4881 - val_accuracy: 0.8000\n",
            "Epoch 266/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8397 - val_loss: 0.6162 - val_accuracy: 0.7750\n",
            "Epoch 267/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8265 - val_loss: 0.5585 - val_accuracy: 0.7917\n",
            "Epoch 268/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3664 - accuracy: 0.8294 - val_loss: 0.5108 - val_accuracy: 0.7583\n",
            "Epoch 269/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8015 - val_loss: 0.4966 - val_accuracy: 0.8000\n",
            "Epoch 270/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8132 - val_loss: 0.5165 - val_accuracy: 0.7750\n",
            "Epoch 271/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3859 - accuracy: 0.8000 - val_loss: 0.4701 - val_accuracy: 0.7833\n",
            "Epoch 272/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8265 - val_loss: 0.4997 - val_accuracy: 0.7750\n",
            "Epoch 273/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8103 - val_loss: 0.4902 - val_accuracy: 0.7917\n",
            "Epoch 274/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8118 - val_loss: 0.4908 - val_accuracy: 0.7917\n",
            "Epoch 275/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8000 - val_loss: 0.5264 - val_accuracy: 0.8000\n",
            "Epoch 276/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.7985 - val_loss: 0.5061 - val_accuracy: 0.7750\n",
            "Epoch 277/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8118 - val_loss: 0.5056 - val_accuracy: 0.7417\n",
            "Epoch 278/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8191 - val_loss: 0.5003 - val_accuracy: 0.7833\n",
            "Epoch 279/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.8176 - val_loss: 0.5036 - val_accuracy: 0.7833\n",
            "Epoch 280/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8103 - val_loss: 0.4929 - val_accuracy: 0.8083\n",
            "Epoch 281/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8118 - val_loss: 0.5530 - val_accuracy: 0.7750\n",
            "Epoch 282/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8338 - val_loss: 0.5679 - val_accuracy: 0.7917\n",
            "Epoch 283/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8338 - val_loss: 0.5021 - val_accuracy: 0.7667\n",
            "Epoch 284/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8368 - val_loss: 0.5227 - val_accuracy: 0.7667\n",
            "Epoch 285/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8265 - val_loss: 0.4437 - val_accuracy: 0.7833\n",
            "Epoch 286/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8118 - val_loss: 0.4601 - val_accuracy: 0.7917\n",
            "Epoch 287/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8176 - val_loss: 0.5028 - val_accuracy: 0.7750\n",
            "Epoch 288/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3926 - accuracy: 0.8015 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 289/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8441 - val_loss: 0.4539 - val_accuracy: 0.8000\n",
            "Epoch 290/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3720 - accuracy: 0.8294 - val_loss: 0.4548 - val_accuracy: 0.7917\n",
            "Epoch 291/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8235 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
            "Epoch 292/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.8118 - val_loss: 0.4666 - val_accuracy: 0.8250\n",
            "Epoch 293/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3819 - accuracy: 0.8279 - val_loss: 0.4683 - val_accuracy: 0.8083\n",
            "Epoch 294/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8118 - val_loss: 0.4652 - val_accuracy: 0.8000\n",
            "Epoch 295/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8250 - val_loss: 0.5136 - val_accuracy: 0.8000\n",
            "Epoch 296/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8309 - val_loss: 0.5253 - val_accuracy: 0.7583\n",
            "Epoch 297/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3638 - accuracy: 0.8368 - val_loss: 0.5051 - val_accuracy: 0.7583\n",
            "Epoch 298/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8265 - val_loss: 0.5323 - val_accuracy: 0.7667\n",
            "Epoch 299/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8162 - val_loss: 0.5196 - val_accuracy: 0.7667\n",
            "Epoch 300/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8368 - val_loss: 0.5491 - val_accuracy: 0.7917\n",
            "Epoch 301/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8029 - val_loss: 0.5485 - val_accuracy: 0.7917\n",
            "Epoch 302/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.7941 - val_loss: 0.4988 - val_accuracy: 0.7833\n",
            "Epoch 303/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8294 - val_loss: 0.5171 - val_accuracy: 0.7667\n",
            "Epoch 304/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8265 - val_loss: 0.5195 - val_accuracy: 0.7667\n",
            "Epoch 305/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8176 - val_loss: 0.5857 - val_accuracy: 0.7750\n",
            "Epoch 306/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.7985 - val_loss: 0.4899 - val_accuracy: 0.7833\n",
            "Epoch 307/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.7956 - val_loss: 0.5072 - val_accuracy: 0.8083\n",
            "Epoch 308/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8221 - val_loss: 0.4730 - val_accuracy: 0.7917\n",
            "Epoch 309/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8426 - val_loss: 0.5359 - val_accuracy: 0.7917\n",
            "Epoch 310/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3763 - accuracy: 0.8324 - val_loss: 0.5077 - val_accuracy: 0.7583\n",
            "Epoch 311/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3704 - accuracy: 0.8309 - val_loss: 0.5215 - val_accuracy: 0.7833\n",
            "Epoch 312/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8191 - val_loss: 0.5280 - val_accuracy: 0.7667\n",
            "Epoch 313/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8088 - val_loss: 0.5602 - val_accuracy: 0.7500\n",
            "Epoch 314/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8294 - val_loss: 0.5443 - val_accuracy: 0.7583\n",
            "Epoch 315/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8559 - val_loss: 0.5310 - val_accuracy: 0.7250\n",
            "Epoch 316/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3621 - accuracy: 0.8368 - val_loss: 0.4407 - val_accuracy: 0.7917\n",
            "Epoch 317/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.8426 - val_loss: 0.5181 - val_accuracy: 0.7583\n",
            "Epoch 318/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8235 - val_loss: 0.5412 - val_accuracy: 0.7667\n",
            "Epoch 319/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8250 - val_loss: 0.5306 - val_accuracy: 0.7917\n",
            "Epoch 320/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8368 - val_loss: 0.5142 - val_accuracy: 0.7750\n",
            "Epoch 321/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8015 - val_loss: 0.5293 - val_accuracy: 0.7583\n",
            "Epoch 322/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8368 - val_loss: 0.5402 - val_accuracy: 0.7833\n",
            "Epoch 323/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8426 - val_loss: 0.6029 - val_accuracy: 0.7667\n",
            "Epoch 324/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8162 - val_loss: 0.5160 - val_accuracy: 0.7750\n",
            "Epoch 325/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8412 - val_loss: 0.5295 - val_accuracy: 0.7667\n",
            "Epoch 326/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8221 - val_loss: 0.5620 - val_accuracy: 0.7750\n",
            "Epoch 327/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8338 - val_loss: 0.5649 - val_accuracy: 0.7667\n",
            "Epoch 328/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8353 - val_loss: 0.5362 - val_accuracy: 0.7833\n",
            "Epoch 329/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8132 - val_loss: 0.5023 - val_accuracy: 0.7917\n",
            "Epoch 330/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8456 - val_loss: 0.5048 - val_accuracy: 0.7917\n",
            "Epoch 331/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8353 - val_loss: 0.5081 - val_accuracy: 0.7833\n",
            "Epoch 332/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8412 - val_loss: 0.5375 - val_accuracy: 0.8000\n",
            "Epoch 333/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8235 - val_loss: 0.4988 - val_accuracy: 0.8250\n",
            "Epoch 334/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8265 - val_loss: 0.5581 - val_accuracy: 0.7917\n",
            "Epoch 335/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8368 - val_loss: 0.5716 - val_accuracy: 0.7583\n",
            "Epoch 336/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8294 - val_loss: 0.4954 - val_accuracy: 0.7750\n",
            "Epoch 337/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.8676 - val_loss: 0.5164 - val_accuracy: 0.7833\n",
            "Epoch 338/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8353 - val_loss: 0.4741 - val_accuracy: 0.8000\n",
            "Epoch 339/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8382 - val_loss: 0.4985 - val_accuracy: 0.8000\n",
            "Epoch 340/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8382 - val_loss: 0.4802 - val_accuracy: 0.7750\n",
            "Epoch 341/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8353 - val_loss: 0.5574 - val_accuracy: 0.8000\n",
            "Epoch 342/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8309 - val_loss: 0.5292 - val_accuracy: 0.7833\n",
            "Epoch 343/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8515 - val_loss: 0.5347 - val_accuracy: 0.7917\n",
            "Epoch 344/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8500 - val_loss: 0.5471 - val_accuracy: 0.8000\n",
            "Epoch 345/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8529 - val_loss: 0.5560 - val_accuracy: 0.7833\n",
            "Epoch 346/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8294 - val_loss: 0.5521 - val_accuracy: 0.7833\n",
            "Epoch 347/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3768 - accuracy: 0.8265 - val_loss: 0.5223 - val_accuracy: 0.8167\n",
            "Epoch 348/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8294 - val_loss: 0.4996 - val_accuracy: 0.8083\n",
            "Epoch 349/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8206 - val_loss: 0.5286 - val_accuracy: 0.7833\n",
            "Epoch 350/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8529 - val_loss: 0.5263 - val_accuracy: 0.8250\n",
            "Epoch 351/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8529 - val_loss: 0.4928 - val_accuracy: 0.7833\n",
            "Epoch 352/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.8397 - val_loss: 0.5436 - val_accuracy: 0.7917\n",
            "Epoch 353/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8324 - val_loss: 0.5689 - val_accuracy: 0.8000\n",
            "Epoch 354/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8426 - val_loss: 0.4791 - val_accuracy: 0.7917\n",
            "Epoch 355/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.8279 - val_loss: 0.5195 - val_accuracy: 0.7833\n",
            "Epoch 356/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8235 - val_loss: 0.5299 - val_accuracy: 0.7833\n",
            "Epoch 357/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8382 - val_loss: 0.5085 - val_accuracy: 0.8083\n",
            "Epoch 358/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8529 - val_loss: 0.5258 - val_accuracy: 0.7583\n",
            "Epoch 359/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.8353 - val_loss: 0.5189 - val_accuracy: 0.8083\n",
            "Epoch 360/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8294 - val_loss: 0.5219 - val_accuracy: 0.7667\n",
            "Epoch 361/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8441 - val_loss: 0.5158 - val_accuracy: 0.7833\n",
            "Epoch 362/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8147 - val_loss: 0.5699 - val_accuracy: 0.7917\n",
            "Epoch 363/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8368 - val_loss: 0.5592 - val_accuracy: 0.8167\n",
            "Epoch 364/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8559 - val_loss: 0.5452 - val_accuracy: 0.8083\n",
            "Epoch 365/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8426 - val_loss: 0.5678 - val_accuracy: 0.8000\n",
            "Epoch 366/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8485 - val_loss: 0.5995 - val_accuracy: 0.7917\n",
            "Epoch 367/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3375 - accuracy: 0.8426 - val_loss: 0.5975 - val_accuracy: 0.8250\n",
            "Epoch 368/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8515 - val_loss: 0.5415 - val_accuracy: 0.7833\n",
            "Epoch 369/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8471 - val_loss: 0.5071 - val_accuracy: 0.8333\n",
            "Epoch 370/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8574 - val_loss: 0.4975 - val_accuracy: 0.7750\n",
            "Epoch 371/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8574 - val_loss: 0.5205 - val_accuracy: 0.7917\n",
            "Epoch 372/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8441 - val_loss: 0.5083 - val_accuracy: 0.8083\n",
            "Epoch 373/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3220 - accuracy: 0.8382 - val_loss: 0.5811 - val_accuracy: 0.8167\n",
            "Epoch 374/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.8618 - val_loss: 0.6243 - val_accuracy: 0.7917\n",
            "Epoch 375/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8500 - val_loss: 0.4955 - val_accuracy: 0.8083\n",
            "Epoch 376/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8279 - val_loss: 0.4990 - val_accuracy: 0.8250\n",
            "Epoch 377/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8471 - val_loss: 0.5825 - val_accuracy: 0.8167\n",
            "Epoch 378/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8441 - val_loss: 0.5539 - val_accuracy: 0.8000\n",
            "Epoch 379/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8500 - val_loss: 0.5209 - val_accuracy: 0.8000\n",
            "Epoch 380/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8382 - val_loss: 0.5561 - val_accuracy: 0.8000\n",
            "Epoch 381/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8574 - val_loss: 0.5510 - val_accuracy: 0.7833\n",
            "Epoch 382/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8324 - val_loss: 0.5562 - val_accuracy: 0.7917\n",
            "Epoch 383/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3448 - accuracy: 0.8397 - val_loss: 0.5442 - val_accuracy: 0.7833\n",
            "Epoch 384/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8515 - val_loss: 0.5366 - val_accuracy: 0.8000\n",
            "Epoch 385/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8368 - val_loss: 0.5864 - val_accuracy: 0.7833\n",
            "Epoch 386/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8294 - val_loss: 0.5584 - val_accuracy: 0.7500\n",
            "Epoch 387/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.8529 - val_loss: 0.5296 - val_accuracy: 0.8083\n",
            "Epoch 388/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8397 - val_loss: 0.5504 - val_accuracy: 0.7833\n",
            "Epoch 389/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8529 - val_loss: 0.5909 - val_accuracy: 0.7917\n",
            "Epoch 390/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8294 - val_loss: 0.5431 - val_accuracy: 0.8250\n",
            "Epoch 391/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8397 - val_loss: 0.5137 - val_accuracy: 0.7917\n",
            "Epoch 392/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3590 - accuracy: 0.8559 - val_loss: 0.4699 - val_accuracy: 0.8167\n",
            "Epoch 393/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3543 - accuracy: 0.8397 - val_loss: 0.4961 - val_accuracy: 0.8000\n",
            "Epoch 394/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8574 - val_loss: 0.5313 - val_accuracy: 0.8083\n",
            "Epoch 395/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8574 - val_loss: 0.5189 - val_accuracy: 0.8083\n",
            "Epoch 396/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8456 - val_loss: 0.5260 - val_accuracy: 0.7833\n",
            "Epoch 397/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8544 - val_loss: 0.5001 - val_accuracy: 0.8000\n",
            "Epoch 398/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8544 - val_loss: 0.5382 - val_accuracy: 0.8000\n",
            "Epoch 399/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3215 - accuracy: 0.8559 - val_loss: 0.4539 - val_accuracy: 0.8333\n",
            "Epoch 400/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.8324 - val_loss: 0.5173 - val_accuracy: 0.7667\n",
            "Epoch 401/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8618 - val_loss: 0.5028 - val_accuracy: 0.8083\n",
            "Epoch 402/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8397 - val_loss: 0.5367 - val_accuracy: 0.8083\n",
            "Epoch 403/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.8559 - val_loss: 0.5231 - val_accuracy: 0.8083\n",
            "Epoch 404/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2924 - accuracy: 0.8647 - val_loss: 0.5306 - val_accuracy: 0.8000\n",
            "Epoch 405/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.8632 - val_loss: 0.5957 - val_accuracy: 0.8333\n",
            "Epoch 406/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8706 - val_loss: 0.5838 - val_accuracy: 0.8000\n",
            "Epoch 407/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8721 - val_loss: 0.5344 - val_accuracy: 0.8000\n",
            "Epoch 408/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8529 - val_loss: 0.5030 - val_accuracy: 0.7833\n",
            "Epoch 409/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3234 - accuracy: 0.8515 - val_loss: 0.5605 - val_accuracy: 0.8083\n",
            "Epoch 410/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8574 - val_loss: 0.5375 - val_accuracy: 0.8083\n",
            "Epoch 411/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3164 - accuracy: 0.8515 - val_loss: 0.5090 - val_accuracy: 0.8083\n",
            "Epoch 412/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8544 - val_loss: 0.5998 - val_accuracy: 0.7917\n",
            "Epoch 413/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3393 - accuracy: 0.8515 - val_loss: 0.5924 - val_accuracy: 0.8000\n",
            "Epoch 414/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8147 - val_loss: 0.5422 - val_accuracy: 0.8167\n",
            "Epoch 415/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.8588 - val_loss: 0.5137 - val_accuracy: 0.8000\n",
            "Epoch 416/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3184 - accuracy: 0.8544 - val_loss: 0.6009 - val_accuracy: 0.8000\n",
            "Epoch 417/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.8632 - val_loss: 0.5754 - val_accuracy: 0.8000\n",
            "Epoch 418/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8559 - val_loss: 0.6420 - val_accuracy: 0.7500\n",
            "Epoch 419/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2830 - accuracy: 0.8735 - val_loss: 0.6058 - val_accuracy: 0.8000\n",
            "Epoch 420/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8603 - val_loss: 0.6781 - val_accuracy: 0.7500\n",
            "Epoch 421/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3040 - accuracy: 0.8706 - val_loss: 0.5588 - val_accuracy: 0.7750\n",
            "Epoch 422/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.8397 - val_loss: 0.5696 - val_accuracy: 0.7833\n",
            "Epoch 423/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8647 - val_loss: 0.5960 - val_accuracy: 0.8333\n",
            "Epoch 424/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.8765 - val_loss: 0.6328 - val_accuracy: 0.7917\n",
            "Epoch 425/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.8618 - val_loss: 0.6119 - val_accuracy: 0.7917\n",
            "Epoch 426/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.8618 - val_loss: 0.5712 - val_accuracy: 0.8083\n",
            "Epoch 427/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3166 - accuracy: 0.8456 - val_loss: 0.5940 - val_accuracy: 0.8000\n",
            "Epoch 428/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8471 - val_loss: 0.5416 - val_accuracy: 0.8000\n",
            "Epoch 429/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3102 - accuracy: 0.8588 - val_loss: 0.5976 - val_accuracy: 0.7917\n",
            "Epoch 430/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3026 - accuracy: 0.8632 - val_loss: 0.5547 - val_accuracy: 0.8000\n",
            "Epoch 431/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3038 - accuracy: 0.8662 - val_loss: 0.5466 - val_accuracy: 0.7833\n",
            "Epoch 432/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.8824 - val_loss: 0.5884 - val_accuracy: 0.7750\n",
            "Epoch 433/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8632 - val_loss: 0.5412 - val_accuracy: 0.7917\n",
            "Epoch 434/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8603 - val_loss: 0.6470 - val_accuracy: 0.7833\n",
            "Epoch 435/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8485 - val_loss: 0.5375 - val_accuracy: 0.8167\n",
            "Epoch 436/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8574 - val_loss: 0.5236 - val_accuracy: 0.7917\n",
            "Epoch 437/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2957 - accuracy: 0.8647 - val_loss: 0.5533 - val_accuracy: 0.7833\n",
            "Epoch 438/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.8338 - val_loss: 0.6133 - val_accuracy: 0.8083\n",
            "Epoch 439/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8265 - val_loss: 0.5769 - val_accuracy: 0.7917\n",
            "Epoch 440/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3123 - accuracy: 0.8632 - val_loss: 0.5518 - val_accuracy: 0.7750\n",
            "Epoch 441/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8500 - val_loss: 0.5549 - val_accuracy: 0.7833\n",
            "Epoch 442/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3228 - accuracy: 0.8632 - val_loss: 0.5493 - val_accuracy: 0.8000\n",
            "Epoch 443/500\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 0.3245 - accuracy: 0.8544 - val_loss: 0.5389 - val_accuracy: 0.7917\n",
            "Epoch 444/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.2939 - accuracy: 0.8794 - val_loss: 0.5630 - val_accuracy: 0.8000\n",
            "Epoch 445/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.8632 - val_loss: 0.5422 - val_accuracy: 0.8000\n",
            "Epoch 446/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3042 - accuracy: 0.8662 - val_loss: 0.5542 - val_accuracy: 0.8083\n",
            "Epoch 447/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3188 - accuracy: 0.8588 - val_loss: 0.6050 - val_accuracy: 0.8250\n",
            "Epoch 448/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2987 - accuracy: 0.8397 - val_loss: 0.6015 - val_accuracy: 0.8000\n",
            "Epoch 449/500\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 0.3342 - accuracy: 0.8397 - val_loss: 0.6020 - val_accuracy: 0.7667\n",
            "Epoch 450/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.3074 - accuracy: 0.8500 - val_loss: 0.5820 - val_accuracy: 0.8000\n",
            "Epoch 451/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2934 - accuracy: 0.8544 - val_loss: 0.5230 - val_accuracy: 0.8000\n",
            "Epoch 452/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.8618 - val_loss: 0.5500 - val_accuracy: 0.7917\n",
            "Epoch 453/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8397 - val_loss: 0.5815 - val_accuracy: 0.7917\n",
            "Epoch 454/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.8574 - val_loss: 0.5590 - val_accuracy: 0.7917\n",
            "Epoch 455/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8515 - val_loss: 0.6055 - val_accuracy: 0.7750\n",
            "Epoch 456/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.8618 - val_loss: 0.6175 - val_accuracy: 0.7750\n",
            "Epoch 457/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8529 - val_loss: 0.5513 - val_accuracy: 0.8000\n",
            "Epoch 458/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8588 - val_loss: 0.6391 - val_accuracy: 0.8000\n",
            "Epoch 459/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2813 - accuracy: 0.8735 - val_loss: 0.6514 - val_accuracy: 0.8083\n",
            "Epoch 460/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2978 - accuracy: 0.8618 - val_loss: 0.5943 - val_accuracy: 0.7833\n",
            "Epoch 461/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.8765 - val_loss: 0.5925 - val_accuracy: 0.8000\n",
            "Epoch 462/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.8750 - val_loss: 0.6479 - val_accuracy: 0.7917\n",
            "Epoch 463/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8515 - val_loss: 0.5942 - val_accuracy: 0.8083\n",
            "Epoch 464/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.8647 - val_loss: 0.6892 - val_accuracy: 0.8000\n",
            "Epoch 465/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3152 - accuracy: 0.8603 - val_loss: 0.6030 - val_accuracy: 0.8000\n",
            "Epoch 466/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2879 - accuracy: 0.8647 - val_loss: 0.6094 - val_accuracy: 0.7833\n",
            "Epoch 467/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8529 - val_loss: 0.6603 - val_accuracy: 0.7833\n",
            "Epoch 468/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2763 - accuracy: 0.8794 - val_loss: 0.6464 - val_accuracy: 0.8000\n",
            "Epoch 469/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2729 - accuracy: 0.8647 - val_loss: 0.5852 - val_accuracy: 0.8083\n",
            "Epoch 470/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2661 - accuracy: 0.8765 - val_loss: 0.5991 - val_accuracy: 0.8083\n",
            "Epoch 471/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3054 - accuracy: 0.8485 - val_loss: 0.5460 - val_accuracy: 0.7833\n",
            "Epoch 472/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.2972 - accuracy: 0.8706 - val_loss: 0.6644 - val_accuracy: 0.7833\n",
            "Epoch 473/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3468 - accuracy: 0.8338 - val_loss: 0.6778 - val_accuracy: 0.7583\n",
            "Epoch 474/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8559 - val_loss: 0.5981 - val_accuracy: 0.7750\n",
            "Epoch 475/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2884 - accuracy: 0.8676 - val_loss: 0.6244 - val_accuracy: 0.8083\n",
            "Epoch 476/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8618 - val_loss: 0.6229 - val_accuracy: 0.8000\n",
            "Epoch 477/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2726 - accuracy: 0.8824 - val_loss: 0.6830 - val_accuracy: 0.8167\n",
            "Epoch 478/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2771 - accuracy: 0.8691 - val_loss: 0.6604 - val_accuracy: 0.8333\n",
            "Epoch 479/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8794 - val_loss: 0.6026 - val_accuracy: 0.7833\n",
            "Epoch 480/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3096 - accuracy: 0.8500 - val_loss: 0.5533 - val_accuracy: 0.8083\n",
            "Epoch 481/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2991 - accuracy: 0.8706 - val_loss: 0.5732 - val_accuracy: 0.8083\n",
            "Epoch 482/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2782 - accuracy: 0.8735 - val_loss: 0.5686 - val_accuracy: 0.7833\n",
            "Epoch 483/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.8471 - val_loss: 0.6241 - val_accuracy: 0.7667\n",
            "Epoch 484/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.3429 - accuracy: 0.8368 - val_loss: 0.5620 - val_accuracy: 0.8000\n",
            "Epoch 485/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.8706 - val_loss: 0.5427 - val_accuracy: 0.7750\n",
            "Epoch 486/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.8706 - val_loss: 0.5066 - val_accuracy: 0.8083\n",
            "Epoch 487/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3005 - accuracy: 0.8721 - val_loss: 0.5232 - val_accuracy: 0.8000\n",
            "Epoch 488/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8559 - val_loss: 0.5518 - val_accuracy: 0.8000\n",
            "Epoch 489/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.8574 - val_loss: 0.5265 - val_accuracy: 0.7583\n",
            "Epoch 490/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2680 - accuracy: 0.8765 - val_loss: 0.5447 - val_accuracy: 0.8250\n",
            "Epoch 491/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.8779 - val_loss: 0.5550 - val_accuracy: 0.8250\n",
            "Epoch 492/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.8794 - val_loss: 0.5191 - val_accuracy: 0.8417\n",
            "Epoch 493/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2434 - accuracy: 0.8779 - val_loss: 0.6115 - val_accuracy: 0.8333\n",
            "Epoch 494/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.8809 - val_loss: 0.5924 - val_accuracy: 0.8250\n",
            "Epoch 495/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2674 - accuracy: 0.8824 - val_loss: 0.5781 - val_accuracy: 0.8167\n",
            "Epoch 496/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.8662 - val_loss: 0.5962 - val_accuracy: 0.8083\n",
            "Epoch 497/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8706 - val_loss: 0.5078 - val_accuracy: 0.8167\n",
            "Epoch 498/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8647 - val_loss: 0.6193 - val_accuracy: 0.7833\n",
            "Epoch 499/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8544 - val_loss: 0.5697 - val_accuracy: 0.8083\n",
            "Epoch 500/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3104 - accuracy: 0.8588 - val_loss: 0.5893 - val_accuracy: 0.8250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "IvFgo0PaaGWb",
        "outputId": "efd08217-dd50-453d-c086-0ea2fd51fe7d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         loss  accuracy  val_loss  val_accuracy\n",
              "0    4.277759  0.569118  1.061603      0.591667\n",
              "1    2.794776  0.554412  0.927574      0.575000\n",
              "2    1.576603  0.554412  0.589969      0.658333\n",
              "3    1.476493  0.541176  0.644137      0.625000\n",
              "4    1.357081  0.545588  0.636195      0.633333\n",
              "..        ...       ...       ...           ...\n",
              "495  0.300030  0.866176  0.596220      0.808333\n",
              "496  0.310560  0.870588  0.507766      0.816667\n",
              "497  0.315367  0.864706  0.619277      0.783333\n",
              "498  0.310553  0.854412  0.569738      0.808333\n",
              "499  0.310434  0.858824  0.589283      0.825000\n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-015dbe99-f405-4e54-ae02-b084b83c6ac0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.277759</td>\n",
              "      <td>0.569118</td>\n",
              "      <td>1.061603</td>\n",
              "      <td>0.591667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.794776</td>\n",
              "      <td>0.554412</td>\n",
              "      <td>0.927574</td>\n",
              "      <td>0.575000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.576603</td>\n",
              "      <td>0.554412</td>\n",
              "      <td>0.589969</td>\n",
              "      <td>0.658333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.476493</td>\n",
              "      <td>0.541176</td>\n",
              "      <td>0.644137</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.357081</td>\n",
              "      <td>0.545588</td>\n",
              "      <td>0.636195</td>\n",
              "      <td>0.633333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0.300030</td>\n",
              "      <td>0.866176</td>\n",
              "      <td>0.596220</td>\n",
              "      <td>0.808333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0.310560</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.507766</td>\n",
              "      <td>0.816667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0.315367</td>\n",
              "      <td>0.864706</td>\n",
              "      <td>0.619277</td>\n",
              "      <td>0.783333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.310553</td>\n",
              "      <td>0.854412</td>\n",
              "      <td>0.569738</td>\n",
              "      <td>0.808333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0.310434</td>\n",
              "      <td>0.858824</td>\n",
              "      <td>0.589283</td>\n",
              "      <td>0.825000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-015dbe99-f405-4e54-ae02-b084b83c6ac0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-015dbe99-f405-4e54-ae02-b084b83c6ac0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-015dbe99-f405-4e54-ae02-b084b83c6ac0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot(figsize = (7,6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "SyF4PCkjaIDF",
        "outputId": "06fa571e-851f-4d56-aa09-1dfef6cd33d6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff3a5e29e90>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv4LzxIkaJeq",
        "outputId": "f33f7bce-829e-4330-f477-b54054f099d7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 0.7987 - accuracy: 0.7650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7987205386161804, 0.7649999856948853]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Metrics"
      ],
      "metadata": {
        "id": "sITsYzUvaMRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(x_test)"
      ],
      "metadata": {
        "id": "5dtj4ZKHaNx0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = np.round(predict)"
      ],
      "metadata": {
        "id": "XcmW_UKFadm5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFu9NL6mafaf",
        "outputId": "3fae8be6-6df6-421e-adc5-1051febefbef"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.76        98\n",
            "           1       0.78      0.75      0.77       102\n",
            "\n",
            "    accuracy                           0.77       200\n",
            "   macro avg       0.77      0.77      0.76       200\n",
            "weighted avg       0.77      0.77      0.77       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "sns.heatmap(confusion_matrix(y_test, yhat), annot = True, fmt = '0.0f', cmap = 'magma')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "5vt3piyaaimU",
        "outputId": "d6502684-4872-4d2a-d5c8-59aff5f16c00"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff3a46de350>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARU0lEQVR4nO3dfbBcdX3H8fc3CUFNQCBIEnMFMiMjQoVQHkbFtgjyjJC2DD5RUsTGMsoUkEJkELV2LNhOedJpuRAwUiBEGITRFAwPKg4kkBCKYMLwPIQhRBCQh4zJ3f32j7vEC4S7e8n+djcn79fMmew5u3v2y0zmky+/8zu/E5mJJKmcUd0uQJKqzqCVpMIMWkkqzKCVpMIMWkkqbEzpH6itvtlpDXqLMe85otslqAdlro0NPUet/ouWM2f0qP02+PdaYUcrSYUV72glqaPq9dY/26FW06CVVC0DA61/tkMJaNBKqpYevNvVoJVULSMZOugQg1ZStRi0klSYQStJhRm0klRW1EYw66BDDFpJ1WJHK0mF1Z3eJUll2dFKUmEGrSQV5sUwSSrMMVpJKsyhA0kqzKCVpLLCoJWkwlwmUZIKG8nC3x1i0EqqFmcdSFJhjtFKUmEGrSQV1oMXwzr0sF1J6pCBWuvbMCLiQxFx35DtDxFxckRsExELIuLhxp9bNyvJoJVULfV669swMvOhzJyWmdOAPYHXgOuBWcCtmbkTcGtjf1gGraRqaVPQvskBwKOZ+SRwFDCncXwOML3Zlw1aSdVSz5a3iJgZEYuHbDPf5qyfBa5uvJ6Ymc80Xq8EJjYryYthkqolW+9UM7Mf6B/uMxExFjgS+Pp6vp8R0fTqm0ErqVraf8PCocC9mflsY//ZiJicmc9ExGRgVbMTOHQgqVraNOtgiM/xp2EDgBuBGY3XM4Abmp3AjlZStbTxhoWIGAccCHx5yOFzgHkRcQLwJHBMs/MYtJKqpY1DB5n5KjDhTceeZ3AWQssMWknVMoKLYZ1i0EqqFlfvkqTCDFpJKqz12QQdY9BKqhY7WkkqzPVoJamwHlyP1qCVVC0OHUhSYV4Mk6TC7GglqTCDVpIKM2glqawcQdBGwTqGMmglVYvTuySpsAFvWJCkshyjlaTCDNpNx+NPPMupp/9w3f6Kp5/jpBMP47hjP8n/XP1Lrr7mDkaNGsVf/cWunHbKUd0rVB3T19fHj350ORMnbkdm0t8/mwsvvIjvfe8cPv3pw1mzZi2PPvooxx//JV566aVul7vRGsnFsE6JLDxwXFt9c+/9V3dYrVZnv4O+wdwrvsaKp5/j4kt/zn9f9GXGjt2M53//MhO22aLbJXbcmPcc0e0SOm7SpElMnjyZpUuXMn78eJYsWcT06UfT1zeF2267nVqtxjnnfBeAWbPO7HK13ZG5doMnAtTO+4eWM2f0KZd0ZOKBT8HtgIWLHmL7vm2Z8v5tmDvv13zp+AMZO3YzgE0yZDdVK1euZOnSpQC88sorLFu2nClT3s+CBbdQqw3eNrpw4SL6+vq6WebGr56tbx3SdOggInYGjgKmNA49DdyYmctKFlYl82++l8MO3ROAJ578HUvufZQLvv9TNt98DP98ynQ+8mc7dLlCddoOO+zAHntMY9Giu99w/Itf/HuuuebHXaqqImq9N+tg2I42Is4A5jI4r/fuxhbA1RExa5jvzYyIxRGx+JLZ89tZ70ZnzdoBbv/lAxx84DRgcBjhpT+8xtwrTuW0k6dz6umXU3r4Rr1l3LhxXHfdPE4++Wu8/PLL646feeYsBgYGuPLKq7pY3cYv661vndKsoz0B2DUz1w49GBH/CTzI4PPN3yIz+4F+cIz2jl//ll127mPbCVsCMGnieznwgN2ICHb7yA6MGhW88MIrbOMQwiZhzJgxXHfdPK688mquv/4n647PmHEcRxxxOAcccFAXq6uIHrwY1myMtg68fz3HJzfeUxPzb7qXww7Zc93+/p/cjbvveRiAJ55cxdq1Nbbeeny3ylOHzZ59CcuWLee8885fd+zggw/i9NO/xpFH/jWrV6/uYnUVsRGO0Z4M3BoRDwNPNY5tD3wQ+GrJwqrgtdV/5M6Fy/nWWZ9Zd+xvpn+Us755FUf+7b+x2Waj+e53jiWiU3dcq5v23XdfjjvuWO6//zcsXboYgDPPPIsLLzyPzTffnAULbgIGL4ideOJXulnqRq2TQwKtajq9KyJGAfvwxoth92RmS6vrbupDB1q/TXF6l5prx/SutWfPaDlzNvuXOR3pcprOOsjMOrCwA7VI0gbrxRsWvDNMUrX04NCBQSupWnqvoTVoJVVLLw4deAuupGqpj2BrIiK2iohrI2J5RCyLiI9FxDYRsSAiHm78uXWz8xi0kiolB1rfWnABcFNm7gzsDiwDZgG3ZuZOwK2N/WEZtJIqpV234EbEe4G/BGYDZOaazHyRwbVf5jQ+NgeY3qwmg1ZStbRv6GAq8Dvg8ohYGhGXRsQ4YGJmPtP4zEpgYrMTGbSSKiWz9W3oAliNbeaQU40B/hz4r8zcA3iVNw0T5OAdX02vvjnrQFKljOQW3KELYK3HCmBFZi5q7F/LYNA+GxGTM/OZiJgMrGr2O3a0kqqlTUMHmbkSeCoiPtQ4dADwW+BGYEbj2AzghmYl2dFKqpR6S6uwtOwk4MqIGAs8BhzPYIM6LyJOAJ4Ejml2EoNWUrXU27dOTGbeB+y1nrcOGMl5DFpJldKLyyQatJIqJbP31nc2aCVVih2tJBVWr9nRSlJR2caLYe1i0EqqlCZP5+oKg1ZSpXgxTJIKc+hAkgpz6ECSCqvVem8JF4NWUqXY0UpSYV4Mk6TCDFpJKqxu0EpSWd6CK0mF2dFKUmGO0UpSYXa0klSYHa0kFdaD634btJKqpVb3FlxJKsqhA0kqrO5aB5JUlh2tJBVWx6CVpKJcJlGSChtIZx1IUlF2tJJUmLfgSlJh6cUwSSrLebSSVFitjRfDIuIJ4GWgBgxk5l4RsQ1wDbAj8ARwTGa+MNx5eu/ynCRtgHq2vrXok5k5LTP3auzPAm7NzJ2AWxv7wzJoJVVKEi1v79BRwJzG6znA9GZfMGglVcpIOtqImBkRi4dsM990ugR+HhFLhrw3MTOfabxeCUxsVpNjtJIqZSTTuzKzH+gf5iOfyMynI2I7YEFELH/T9zMimg5CFA/acVt9qfRPaCM0UFvQ7RJUUe2cdJCZTzf+XBUR1wP7AM9GxOTMfCYiJgOrmp3HoQNJlTKQ0fI2nIgYFxFbvP4aOAh4ALgRmNH42AzghmY1OXQgqVLauEziROD6iIDBrLwqM2+KiHuAeRFxAvAkcEyzExm0kiqlXc8My8zHgN3Xc/x54ICRnMuglVQp3hkmSYW51oEkFWZHK0mF1VwmUZLKsqOVpMIco5WkwuxoJamwds2jbSeDVlKleDFMkgpz6ECSCuvBnDVoJVWLjxuXpMLsaCWpMMdoJamwmkErSWXVvTNMkspKO1pJKss7wySpMC+GSVJhPZizBq2kaqn14NiBQSupUnowZw1aSdXiGK0kFdaDOWvQSqoWO1pJKsyFvyWpMDtaSSqsB3PWoJVULXa0klRY9mBPO6rbBUhSO9Wz9a0VETE6IpZGxE8b+1MjYlFEPBIR10TE2GbnMGglVUotW99a9E/AsiH75wLnZeYHgReAE5qdwKCVVCmZrW/NREQfcDhwaWM/gP2BaxsfmQNMb3Yex2glVUqb1zo4Hzgd2KKxPwF4MTMHGvsrgCnNTmJHK6lSRjJGGxEzI2LxkG3m6+eJiCOAVZm5ZENrsqOVVCkjeZRNZvYD/W/z9r7AkRFxGPAuYEvgAmCriBjT6Gr7gKeb/Y4draRKadfFsMz8emb2ZeaOwGeB2zLzC8DtwNGNj80AbmhWk0ErqVLqI9jeoTOAUyPiEQbHbGc3+4JDB5IqJQs8BjczfwH8ovH6MWCfkXzfoJVUKd6CK0mF9WDOGrSSqsWOVpIKqxUYo91QBq2kSrGjlaTCerChNWglVUu9By+HGbSF9PVNZvbs89lu4rZkJrNnX8UPvn8ZZ511Csd/8fM899zzAJx99rncfNPtXa5WnfL44ys59dRL1u2veOo5Tjrp09x332M8/sSzALz8h9VsseW7uf76b3SrzI2aHe0mZGCgxhlnfIf77nuA8ePHcdfC+dx6yx0AXHTRpZx/3sVdrlDdMHXqpHUBWqvV2W+/MzjgU3tw3IxPrfvMuef+mC3Gv7tbJW702rx6V1sYtIWsXLmKlStXAfDKK6+yfPkjTJkyqctVqZcsXLic7T/wPqZMmbDuWGZy801LuOzyU7pY2cat1oNXw1zroAN22KGPabvvyt13LwXgxH+cwT2Lf87FF/8HW2313i5Xp26ZP/8eDjt87zccW7L4YSZM2IIdd5zYpao2fnWy5a1T3nHQRsTxw7y3bo3HWu2Vd/oTlTBu3Hu4eu7FnHbat3j55Vfo77+CD3/4E+yz98GsXLmKc891HG5TtGbNALff9n8cfPCebzj+s5/dw2GHj+g2er1JO5+w0C4b0tF+++3eyMz+zNwrM/caPXr8BvzExm3MmDHMvaafuXN/wg033ATAqlXPUa/XyUwuu+wq9tp7WperVDfccccD7LLL9my77Zbrjg0M1LjllqUceuheXaxs49eLHe2wY7QRcf/bvQX4/zZNXHzxv7N8+cNceMGfrjJPmrTdurHbI486hAcffKhb5amL5v/srcMGd921jKlTJzFp0tZdqqoaNsZZBxOBgxl80uNQAdxZpKKK+PjH9+YLxx7Nb36zjEV3D3azZ599Lp855ih2231XMpMnn1zBV78yq8uVqtNee+2P3HnnMr717WPfcPx/5y9+S/hq5Aay9+YdxHBrN0bEbODyzPz1et67KjM/3+wH3rX5B3rw3xd126urr+h2CepBo0ftFxt6jsO2/nrLmTP/hX/b4N9rxbAdbWa+7fPKWwlZSeq03utnnUcrqWK8BVeSCivxKJsNZdBKqhQ7WkkqrEat2yW8hUErqVLsaCWpMINWkgqr9+AEL4NWUqVkGLSSVJRDB5JUWI2BbpfwFgatpEqpO3QgSWV5MUySCjNoJamwNGglqawaa9tynoh4F/ArYHMGs/LazPxmREwF5gITgCXA32XmmuHO5VNwJVVKPeotb038Edg/M3cHpgGHRMRHgXOB8zLzgww+feZt1+1+nUErqVLq1FrehpODXn+M92aNLYH9gWsbx+cA05vVZNBKqpTWn4FbJyJmRsTiIdvMoeeKiNERcR+wClgAPAq8mJmvT9ZdAUxpVpNjtJIqpZ6tL5OYmf1A/zDv14BpEbEVcD2w8zupyaCVVCklZh1k5osRcTvwMWCriBjT6Gr7gKebfd+hA0mVUmNty9twIuJ9jU6WiHg3cCCwDLgdOLrxsRnADc1qsqOVVClt7GgnA3MiYjSDTem8zPxpRPwWmBsR/wosBWY3O5FBK6lScgRjtMOfJ+8H9ljP8ceAfUZyLoNWUqV4C64kFZY+nFGSysq0o5WkomrZnrUO2smglVQprt4lSYU5dCBJhXkxTJIKs6OVpMJq6VNwJakoO1pJKqxdt+C2k0ErqVKc3iVJhTl0IEmFGbSSVFjdWQeSVJYdrSQVZ9BKUlF2tJJUmNO7JKkwO1pJKixd+FuSSrOjlaSyHDqQpLKS7HYJb2HQSqoYO1pJKqoXZx1EZu+12VUVETMzs7/bdai3+Pei+kZ1u4BNzMxuF6Ce5N+LijNoJakwg1aSCjNoO8txOK2Pfy8qzothklSYHa0kFWbQSlJhBm2HRMQhEfFQRDwSEbO6XY+6LyIui4hVEfFAt2tRWQZtB0TEaOAHwKHALsDnImKX7lalHvBD4JBuF6HyDNrO2Ad4JDMfy8w1wFzgqC7XpC7LzF8Bv+92HSrPoO2MKcBTQ/ZXNI5J2gQYtJJUmEHbGU8DHxiy39c4JmkTYNB2xj3AThExNSLGAp8FbuxyTZI6xKDtgMwcAL4K3AwsA+Zl5oPdrUrdFhFXA3cBH4qIFRFxQrdrUhnegitJhdnRSlJhBq0kFWbQSlJhBq0kFWbQSlJhBq0kFWbQSlJh/w9d5rxPzbRYGwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}